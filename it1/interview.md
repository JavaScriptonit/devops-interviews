# Список вопросов:

## Собеседование с IT-One:

-----------------------

# Вопросы из записи в iCloud (ИТ1 тех собес 1/2):

# ОПЫТ:

## 1. Есть что-то такое что запомнилось как большой успех? Не успех работы, а что приятно лично вспоминать. (ОПЫТ)
https://www.linkedin.com/in/vitalylobachev/details/experience/ - пример опыта работа Лабочева Виталия

**Достижения в работе**:

1. Рефакторинг и приведение к единому стандарту инфраструктуры команд Банка что позволяет экономить время на конфигурацию сервера/сервисов.
2. Документация всей проделанной работы на досках в Jira, в Confluence, в пайплайнах, скриптах и конфигах что позволяет экономить своё время и сотрудников на изучение инфры и обучение сотрудников.
3. Настройка мониторинга для всех команд (серверов, устройств, контейнеров, сервисов и бд)
4. Настройка CI/CD для тестирования, сборок и доставки кода для разных команд Банка.
5. Автоматизация нотификаций, очистки логов/данных на серверах, создания УЗ, регистрации раннеров, выпуска сертификатов.
6. Траблшутинг проблем, сетевых доступов и пайплайнов.

## 2. Факапы за время работы DevOps? (ОПЫТ)

1. Дали чужой PROD сервер с рабочим allure-server и запущенными приложениями. Не 1 сервер - 1 сервис, а прод сервер с 30 запущенными сервисами и регулярно запускающимися авто-тестами в несколько потоков.
    1. Согласился разобраться с проблемами на проблемном сервере.
    2. Не изучил всю архитектуру и не сразу нашел корень проблемы.
    3. Ко мне пришли с проблемой что отчеты перестали писаться на диск. Нехватка места или проблема с allure-server.
    4. На сервере были внесены изменения в конфигурации сотрудником и был ребут сервака.
    5. После ребута отлетели mount диски и я ЭТО не проверил/не нашел сразу.
    6. Отчеты стали писаться на другой диск. 
    7. Забилась /root директория с др диском. 
    8. Очистка памяти не помогала.
    9. Приложения падали с ошибкой из-за нехватки места.
    10. Не сразу нашел ссылки на директории, в которые писались логи. (Символические ссылки)
2. Потратил уйму времени на локализацию главной проблемы что диск был отмонтирован и повлёк за собой пачку проблем.

## 3. Нужно зайти на сервер и посмотреть потребление ресурсов. Процессор/Память/Диск/Сеть. Какими командами? (Linux)

Просмотр потребления ресурсов (процессор, память, диск, сеть) на сервере Linux:

1. `top`, `htop` - Онлайн просмотр MEMORY и CPU, NI (приоритет)

2. `free -h` - Просмотр использования памяти. 
    1. `lscpu` - информация о процессах
    2. `ps aux` - инфо о процессах (PID/USER/MEM/TIME/CPU)

3. `df -h`, `df -T`, `df -i` - Просмотр использования диска
    1. `du -axh --max-depth=1 /var` - folder used memory
    2. `tune2fs -l /dev/mapper/vg01-lv_var` - инфо по диску
    3. `ls -ltr | tail -1` - самый свежий файл
        1. `ls -lt | tail -1` - самый старый файл

4. `iftop`, `ip -s link` - Просмотр использования сети

5. `vgs` - volume groups

6. `iptables` - утилита для настройки правил брандмауэра в Linux. С помощью `iptables` можно управлять трафиком сетевых пакетов, определять, какие пакеты разрешены или блокированы, настраивать NAT (Network Address Translation), а также многое другое.

    Ключевые моменты об `iptables` (https://habr.com/ru/articles/747616/):

    1. **Таблицы**: `iptables` имеет различные таблицы, такие как `filter`, `nat`, `mangle`, `raw`, `security`. Каждая таблица используется для определенных целей, например, фильтрации пакетов (`filter`), NAT (`nat`), изменения заголовков пакетов (`mangle`).

    2. **Цепочки**: В рамках каждой таблицы существуют различные цепочки, такие как `INPUT`, `OUTPUT`, `FORWARD`. Цепочки определяют, куда направляются пакеты и какие правила применяются к ним.

    3. **Правила**: Правила `iptables` определяют, что делать с пакетами, которые проходят через брандмауэр. Правила могут разрешать, блокировать, перенаправлять или изменять пакеты в соответствии с заданными условиями.

    Через `iptables` можно просматривать текущие правила брандмауэра, смотреть статистику использования правил, добавлять новые правила, удалять и изменять существующие правила и т.д. 

    Например:

    1. `iptables -t nat -L` используется для просмотра правил NAT в таблице `nat`.
    2. `iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 8080` - для редиректа трафика с `--dport 80` до `--to-port 8080`
    3. `iptables -A INPUT -p tcp --dport 22 -m state --state NEW -m limit --limit 3/min -j ACCEPT` - для ограничения скорости
    4. `iptables -A INPUT -j LOG --log-prefix "Dropped Packet: " iptables -A INPUT -j DROP` - логирование всех отброшенных пакетов

## 4. Чем отличается системное от пользовательского времени (процессорное)? (Linux)

1. Пользовательское время — это время, затраченное процессором на выполнение команд, заданных пользовательской программой. 
2. Системное время — это время, затраченное на выполнение операционной системой и различными системными службами. 
3. Процессорное время может быть разделено между несколькими задачами или программами.

## 5. В Allure-server - ошибка: "No space left on device" и путь. df -h показывает что место есть. В чем проблема? (Linux)

1. Закончились Inodes (мета данные).
2. Проверю кол-во свободных инод на диске `df -i` или `df -ih`
3. Нужно увеличить размер диска что повлечет увеличение свободных inodes.
    1. Либо изменить файловую систему на более подходящую под задачи сервиса/сервера.
    2. `df -T` - fs Type: `ext4` (улучшенная версия ext3), `btrfs`, `XFS`, `FAT32`, `NTFS`:
        1. `ext4` - max размер раздела: 50-100тб, max размер файла: 16тб, max кол-во файлов - 4млрд
        2. `XFS` - max размер раздела: 8 экзабайт, max размер файла: 8 экзабайт, max кол-во файлов - 2 в 64 степени

## 6. Как потюнить Файловую систему? Какой командой её можно улучшить? (Linux)

Настройка и оптимизация файловой системы в Linux может повысить производительность и эффективность работы сервера. Одной из команд, которая может помочь улучшить файловую систему, является `tune2fs`.

`Tune2fs` - это утилита для настройки параметров файловых систем ext2/ext3/ext4. Некоторые параметры, которые можно настроить с помощью `tune2fs`:

1. **Интервал проверки файловой системы**: Можно изменить интервал проверки файловой системы на наличие ошибок при помощи опции `-c` (по количеству монтирований) или `-i` (по времени).

2. **Интервал записи журнала**: Можно изменить интервал записи журнала файловой системы с помощью опции `-J`.

3. **Размер журнала**: Можно изменить размер журнала файловой системы с помощью опции `-j`.

4. **Метка файловой системы**: Можно установить метку файловой системы с помощью опции `-L`.

5. **Максимальное количество монтирований**: Можно установить максимальное количество монтирований перед проверкой файловой системы с помощью опции `-C`.

Примеры использования `tune2fs`:

- Установить интервал проверки файловой системы на 30 дней:
```bash
sudo tune2fs -i 30d /dev/sdX
```

- Установить метку файловой системы:
```bash
sudo tune2fs -L "mylabel" /dev/sdX
```

## 7. Как поднять приоритет выполнения процесса на процессоре? (Linux)

Управлять приоритетом выполнения процессов с помощью утилиты `nice` или команды `renice`. 
Приоритет процесса определяет, как часто процесс получает доступ к процессорным ресурсам. Чем ниже значение приоритета, тем выше приоритет у процесса.

1. **Установка приоритета с помощью `nice`**:
   - Команда `nice` используется для запуска процесса с измененным приоритетом. Чем больше значение приоритета, тем ниже приоритет у процесса.
   - Пример установки приоритета процесса на 10: `nice -n 10 command`
   - В данном примере `command` - это команда, для которой вы хотите изменить приоритет.

2. **Изменение приоритета с помощью `renice`**:
   - Команда `renice` позволяет изменить приоритет уже запущенного процесса.
   - Пример изменения приоритета процесса с PID 123 на 5: `renice 5 -p 123`
   - В данном примере `123` - это идентификатор процесса.

3. **Просмотр текущего приоритета процессов**:
   - Для просмотра текущего приоритета процессов можно использовать команду `top` или `htop`. Приоритет отображается в столбце `NI` (nice value).

Важно помнить, что установка слишком высокого приоритета для процесса может привести к замедлению работы других процессов на системе. Рекомендуется быть осторожным при изменении приоритетов процессов и учитывать потребности других процессов на сервере.

## 8. Символические ссылки и жесткие ссылки. В чем разница? (Linux)

Символические ссылки (`symbolic links`) и жесткие ссылки (`hard links`) - это два способа создания ссылок на файлы в UNIX-подобных операционных системах, таких как Linux. Они имеют разные особенности и применения:

1. **Жесткие ссылки (hard links)**: `ln file1.txt hardlink.txt`
   - Жесткая ссылка - это второе (или более) имя файла, которое указывает на те же данные на диске, что и первое имя.
   - Жесткие ссылки работают только в пределах одной файловой системы.
   - Удаление исходного файла не влияет на жесткие ссылки, так как они указывают на те же данные на диске.
   - Жесткие ссылки не могут быть созданы для директорий.
   - Изменения в одном файле отразятся во всех его жестких ссылках, так как все они указывают на одни и те же данные.
   - Имеет одинаковый id c оригиналом

2. **Символические ссылки (symbolic links)**: `ln -s file1.txt softlink.txt`
   - Символическая ссылка - это специальный файл, который содержит путь к другому файлу или директории.
   - Символические ссылки могут пересекать границы файловых систем и могут указывать на файлы, которые еще не существуют.
   - Если исходный файл удален, символическая ссылка становится битой и не может быть использована.
   - Символические ссылки могут быть созданы для директорий.
   - Изменения в исходном файле не влияют на символическую ссылку, так как она просто содержит путь к файлу.
   - Имеет разные id c оригиналом и является ссылкой (другой тип файла и другой id)

В общем, жесткие ссылки обеспечивают более непосредственное соединение между файлами, в то время как символические ссылки предоставляют более гибкую возможность ссылаться на файлы. Каждый тип ссылок имеет свои особенности и применения, и выбор между ними зависит от конкретной задачи.

`ls -l` - для просмотра информации о ссылках на файлы в столбце links

## 9. Как ограничить процесс по потребляемой оперативной памяти? (Linux)

1. Ограничение потребления оперативной памяти контейнера `gitlab-runner-bank2` в 250MB:

    **Шаг 1:** Найти ID контейнера `gitlab-runner-bank2` - `docker ps`

    **Шаг 2:** Команда `docker stats gitlab-runner-bank2` чтобы увидеть текущее потребление оперативной памяти

    **Шаг 3:** Установить ограничение на потребление оперативной памяти контейнера `docker update --memory 250m gitlab-runner-bank2`


2. Создание процесса в Linux и установки ограничения на его потребление оперативной памяти в 250MB:

    **Шаг 1:** Файл `light_process.sh` для создания процесса:
    ```bash
    #!/bin/bash

    while true
    do
        echo "Light process is running..."
        sleep 1000
    done
    ```

    **Шаг 2**: Сделайте скрипт исполняемым: `chmod +x light_process.sh`

    **Шаг 3**: Запустите скрипт light_process.sh в фоновом режиме: `./light_process.sh &`

    **Шаг 4**: Найдите PID (идентификатор процесса) запущенного процесса, используя команду ps: `ps aux | grep light_process.sh`

    **Шаг 5**: Установите ограничение на потребление оперативной памяти для процесса, используя утилиту cgroups. Создайте cgroup с именем `memory_limit` и установите ограничение в 250MB:
    ```bash
    sudo mkdir /sys/fs/cgroup/memory/memory_limit
    echo 250M > /sys/fs/cgroup/memory/memory_limit/memory.limit_in_bytes
    echo $$ > /sys/fs/cgroup/memory/memory_limit/tasks
    ```

    **Шаг 6**: Посмотреть текущий лимит и после его обновления:
    ```bash
    cat /sys/fs/cgroup/memory/memory_limit/memory.limit_in_bytes 
    9223372036854771712

    echo 250M > /sys/fs/cgroup/memory/memory_limit/memory.limit_in_bytes

    cat /sys/fs/cgroup/memory/memory_limit/memory.limit_in_bytes 
    262144000
    ```
    **Шаг 7**: Добавить PID процесса в созданную группу:
    ```bash
    echo 3327922 > /sys/fs/cgroup/memory/process1/tasks
    cat /sys/fs/cgroup/memory/memory_limit/tasks
    3327922
    3328466
    3329874
    ```

## 10. Что такое DNS? (DNS)
Ответ есть в sber/education/interview.md

1. **Как работает DNS**:
   - **DNS (Domain Name System)** - это система, которая переводит доменные имена в IP-адреса и наоборот. Основные принципы работы DNS:
     - Когда вы вводите доменное имя в веб-браузере, ваш компьютер отправляет запрос DNS-серверу для получения соответствующего IP-адреса.
     - DNS-серверы содержат базы данных с записями DNS, которые соответствуют доменным именам IP-адресам.
     - DNS использует иерархическую структуру доменных имен, где домены разделены точками (например, sregistry.mts.ru).
     - Различные типы записей DNS включают A (IPv4-адрес), AAAA (IPv6-адрес), CNAME (каноническое имя), MX (почтовый сервер) и другие.

2. **Как настроить DNS**:
   - Для настройки DNS необходимо уметь работать с DNS-серверами, добавлять и изменять записи DNS, управлять зонами и кэшированием. Некоторые шаги настройки DNS:
     - Настройка DNS-сервера (например, BIND, Microsoft DNS).
     - Добавление и изменение записей DNS (A, CNAME, MX и т. д.) для привязки доменных имен к IP-адресам.
     - Управление зонами DNS, которые определяют, какие домены и поддомены обслуживает DNS-сервер.
     - Настройка кэширования DNS для ускорения процесса разрешения доменных имен.

3. **DNS безопасность**:
   - Для обеспечения безопасности DNS необходимо защищаться от DDoS-атак, DNS-подделок и других угроз безопасности. Некоторые методы защиты:
     - Использование DNSSEC (DNS Security Extensions) для обеспечения целостности и аутентичности данных DNS.
     - Настройка файрвола для блокировки нежелательных DNS-запросов и защиты от DDoS-атак.
     - Мониторинг и аудит DNS-трафика для обнаружения аномалий и подозрительной активности.
     - Регулярное обновление и усиление конфигурации DNS-серверов для предотвращения уязвимостей.

Чаще всего DevOps инженеры используют специализированные DNS-серверы, такие как BIND, PowerDNS, dnsmasq или другие, для управления DNS-зонами и обеспечения доступности и надежности DNS-сервиса.

Пример использования DNS на Ubuntu сервере Linux:
1. Установка DNS-сервера BIND:
```
sudo apt update
sudo apt install bind9
```

2. Настройка зоны DNS в файле `/etc/bind/named.conf.local`:
```bash
zone "sregistry.mts.ru" {
    type master;
    file "/etc/bind/zones/sregistry.mts.ru.zone";
};
```

3. Создание файла зоны `/etc/bind/zones/sregistry.mts.ru.zone` и добавление записей:
```bash
$TTL    604800
@       IN      SOA     ns1.sregistry.mts.ru. admin.sregistry.mts.ru. (
                2022010101  ; Serial
                604800      ; Refresh
                86400       ; Retry
                2419200     ; Expire
                604800 )    ; Negative Cache TTL
;
@       IN      NS      ns1.sregistry.mts.ru.
@       IN      A       192.168.1.10
www     IN      A       192.168.1.20
```

4. Перезапуск DNS-сервера для применения изменений: `sudo systemctl restart bind9`

Теперь сервер Ubuntu Linux будет использовать настроенный DNS-сервер для разрешения доменных имен в IP-адреса.

## 11. Какие бывают типы записей в DNS? (DNS)

Дополнительно к упомянутым типам записей DNS (A, AAAA, CNAME, MX), существуют и другие распространенные типы записей, вот некоторые из них:

1. **NS (Name Server)** - указывает на авторитетные DNS-серверы для конкретной зоны.
2. **PTR (Pointer)** - используется для обратного маппинга IP-адресов на доменные имена (reverse DNS lookup).
3. **TXT** - позволяет добавлять произвольный текстовый комментарий к доменному имени, часто используется для SPF (Sender Policy Framework) записей для электронной почты.
4. **SRV (Service)** - определяет местоположение службы в сети, таких как серверы электронной почты или VoIP.
5. **SOA (Start of Authority)** - содержит информацию об авторитетности зоны и параметры обслуживания.
6. **CAA (Certification Authority Authorization)** - определяет, какие сертификационные органы имеют право выдавать SSL-сертификаты для данного домена.
7. **SPF (Sender Policy Framework)** - определяет список IP-адресов, которые авторизованы отправлять электронную почту от имени домена.

## 12. Приведи примеры каждого типа записи. (DNS)

Примеры записей для типов A, AAAA, CNAME и MX:

1. **A (IPv4-адрес)**: 
   - Пример записи A: 
     ```
     sregistry.mts.ru. IN A 192.0.2.1
     ```
   В данном примере домен sregistry.mts.ru связан с IPv4-адресом 192.0.2.1.

2. **AAAA (IPv6-адрес)**: 
   - Пример записи AAAA: 
     ```
     sregistry.mts.ru. IN AAAA 2001:0db8:85a3:0000:0000:8a2e:0370:7334
     ```
   В данном примере домен sregistry.mts.ru связан с IPv6-адресом 2001:0db8:85a3:0000:0000:8a2e:0370:7334.

3. **CNAME (каноническое имя)**: 
   - Пример записи CNAME: 
     ```
     www.sregistry.mts.ru. IN CNAME sregistry.mts.ru.
     ```
   В данном примере поддомен www.sregistry.mts.ru перенаправляется на домен sregistry.mts.ru.

4. **MX (почтовый сервер)**: 
   - Пример записи MX: 
     ```
     sregistry.mts.ru. IN MX 10 mail.sregistry.mts.ru.
     ```
   В данном примере почтовые сообщения для домена sregistry.mts.ru будут отправляться на почтовый сервер mail.sregistry.mts.ru с приоритетом 10.

Каждая запись имеет свой синтаксис и структуру, которая определяет связь между доменным именем и соответствующими IP-адресами или другими серверами.

## 13. Команды и утилиты чтобы опросить DNS сервер. (DNS)

Существует несколько утилит и команд, которые можно использовать для опроса DNS-сервера и получения информации о доменных записях. Некоторые из наиболее распространенных утилит включают в себя `nslookup`, `dig`, `host` и `nsq`.

1. **nslookup**:
   - Пример использования:
     ```
     nslookup sregistry.mts.ru
     Name: sregistry.mts.ru
     Address: 11.215.144.1
     ```
   Эта команда позволяет выполнить DNS-запрос для домена sregistry.mts.ru и вывести информацию о соответствующих записях.

2. **host**:
   - Пример использования:
     ```bash
     host sregistry.mts.ru
     sregistry.mts.ru has address 11.215.144.1

     host -t MX mail.mtsbank.ru
     mail.mtsbank.ru is an alias for adns.mail.mtsbank.ru.
     ```
   Эта команда позволяет выполнить DNS-запрос для типа записи MX (почтовый сервер) для домена sregistry.mts.ru и вывести информацию о почтовом сервере.

3. **dig** (Domain Information Groper):
   - Пример использования:
     ```bash
     dig AAAA sregistry.mts.ru

     ; <<>> DiG 9.16.48-Ubuntu <<>> AAAA sregistry.mts.ru
     ;; global options: +cmd
     ;; Got answer:
     ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 60238
     ;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 1

     ;; OPT PSEUDOSECTION:
     ; EDNS: version: 0, flags:; udp: 65494
     ;; QUESTION SECTION:
     ;sregistry.mts.ru.              IN      AAAA

     ;; Query time: 0 msec
     ;; SERVER: 127.0.0.53#53(127.0.0.53)
     ;; WHEN: Thu Feb 29 21:08:50 MSK 2024
     ;; MSG SIZE  rcvd: 45
     ```
   1. NOERROR - это означает, что запрос был выполнен успешно и не возникло ошибок.
   2. Ответ: ANSWER: 0 - это означает, что в ответе на запрос не было найдено записей AAAA (IPv6 адресов) для домена sregistry.mts.ru.
   3. Сервер DNS: SERVER: 127.0.0.53#53(127.0.0.53) - запрос был отправлен на локальный DNS сервер с IP-адресом 127.0.0.53.
   4. Время выполнения запроса: Query time: 0 msec - запрос был выполнен за очень короткое время.
   5. Из данного вывода следует, что для домена sregistry.mts.ru отсутствуют записи AAAA (IPv6 адресов). 

Эти утилиты и команды могут быть использованы для проверки доступности DNS-сервера, получения информации о доменных записях, а также для диагностики и анализа проблем с DNS.

## 14. У нас есть директория, у неё права 755. Что это обозначает? (Linux)

Права 755:
1. (4+2+1=7) - владелец файла имеет права на чтение, запись и выполнение
2. (4+0+1=5) - группа и остальные пользователи имеют права только на чтение и выполнение

## 15. Что означает "Выполнение" для директории? (Linux)

1. Право на чтение позволяет пользователю получить список содержимого папки. 
2. Право на запись позволяет создавать и удалять файлы в этой папке. 
3. Право на исполнение разрешает перейти в эту папку:
    1. `cd /Users/andreyshabunov/PhpstormProjects/devops-interviews` - перейти в директорию
    2. `ls -l /Users/andreyshabunov/PhpstormProjects/devops-interviews` - список файлов директории

## 16. У нас есть директория, у неё права 700. Нужно не меняя владельца и права добавить доступ кому-то для работы с этой директорией. Как это сделать? (Linux)

Утилита `setfacl` позволяет управлять расширенными списками контроля доступа (ACL) в Linux:

1. Установить ACL для директории, чтобы включить расширенные списки контроля доступа:
   ```
   setfacl -m u:pberyozkin_adm:rwx /home/ashabunov_adm/test
   ```
   Добавить доступ для pberyozkin_adm

2. Посмотреть текущие ACL для директории:
   ```
   getfacl /home/ashabunov_adm/test/
   ```

3. Вывод команды `getfacl /home/ashabunov_adm/test/`:
    ```
    getfacl: Removing leading '/' from absolute path names
    # file: home/ashabunov_adm/test/
    # owner: ashabunov_adm
    # group: docker
    user::rwx
    user:pberyozkin_adm:rwx         #effective:---
    group::r-x                      #effective:---
    mask::---
    other::---
    ```

## 17. AppArmor и SELinux профиль. Приходилось ли дебажить и настраивать? (Linux)

`AppArmor` и `SELinux` - это две различные системы обязательного контроля доступа в Linux, которые обеспечивают дополнительный уровень безопасности для системы.

1. `AppArmor` (Application Armor) - это система контроля доступа, которая ограничивает возможности программ, устанавливая правила для их исполнения. AppArmor работает на уровне приложений и позволяет определить, какие ресурсы и операции приложение может использовать. Для настройки профилей безопасности в AppArmor используется специальный язык профилей.

2. `SELinux` (Security-Enhanced Linux) - это модуль ядра Linux, который предоставляет механизм обязательного контроля доступа на основе меток безопасности. SELinux управляет доступом к файлам, процессам, портам и другим ресурсам, определяя политики безопасности для различных объектов в системе.

Настройка профилей дебага и настройка в контексте AppArmor и SELinux может включать в себя определение правил доступа для конкретных приложений или сервисов, управление метками безопасности, а также настройку аудита и журналирования для отслеживания событий безопасности.

Обе системы обеспечивают возможность создания профилей безопасности для различных приложений и сервисов, что позволяет усилить защиту системы от различных угроз.

## 18. Что такое CI/CD? (CI/CD)
sber/education/interview.md - 29. Идеальный пайплайн в CI/CD. Какие должны быть шаги?

CI/CD (Continuous Integration/Continuous Delivery) - это практика разработки программного обеспечения, которая объединяет непрерывную интеграцию (CI) и непрерывную поставку (CD) для автоматизации процесса разработки, тестирования и развертывания приложений.

1. **Continuous Integration (непрерывная интеграция)** - это практика, при которой разработчики регулярно объединяют свой код в общий репозиторий, после чего автоматически запускаются сборка и тестирование приложения. Это позволяет выявлять и исправлять конфликты интеграции и ошибки в коде на ранних этапах разработки.

2. **Continuous Delivery (непрерывная поставка)** - это практика, при которой каждое изменение кода, прошедшее успешные тесты в процессе CI, автоматически готово к развертыванию в производственную среду. Это позволяет ускорить процесс доставки новых функций и обновлений пользователям.

CI/CD позволяет командам разработки создавать, тестировать и разворачивать программное обеспечение быстрее и эффективнее, уменьшая риски и повышая качество продукта. Автоматизация процессов CI/CD помогает улучшить скорость разработки, улучшить сотрудничество в команде и упростить управление развертыванием приложений.

## 19. Выкатка на прод. Бэк деплоится на ВМ или bare metal (20 шт). Nginx балансирует запросы клиентов на бэк. Какие есть способы/стратегии деплоя в такую среду чтобы при наличии ошибки отследить/откатить? Стратегии постепенного деплоя.

Для деплоя в среду с несколькими серверами, где бэкенд деплоится на виртуальные машины или физические серверы (bare metal), и запросы балансируются Nginx, важно иметь стратегии деплоя, которые позволяют отслеживать ошибки и в случае необходимости откатывать изменения. Ниже приведены некоторые распространенные стратегии деплоя и методы обработки ошибок:

1. **Стратегии деплоя:**

   - **Blue-Green деплоймент:** При использовании этой стратегии создаются два окружения (Blue и Green). На одном из них работает текущая версия приложения (например, Blue), а на другом развертывается новая версия (Green). После успешного тестирования новой версии, балансировщик трафика переключается на новое окружение. Это позволяет быстро откатиться к предыдущей версии в случае проблем.

   - **Canary деплоймент:** При использовании этой стратегии новая версия приложения постепенно внедряется в производственную среду путем направления только части трафика на нее. Это позволяет постепенно оценивать стабильность новой версии и быстро реагировать на возможные проблемы.

2. **Обработка ошибок и откат изменений:**

   - **Мониторинг и логирование:** Важно настроить мониторинг и логирование на серверах и балансировщике, чтобы быстро обнаруживать ошибки после деплоя.

   - **Автоматизированный откат:** Разработайте процедуру автоматизированного отката изменений в случае обнаружения критических ошибок. Это может включать в себя использование инструментов для управления конфигурациями или CI/CD платформ.

   - **Тестирование перед деплоем:** Проведите тщательное тестирование новой версии приложения перед деплоем в продакшн, чтобы минимизировать риск возникновения ошибок.

   - **Ручной откат:** Если автоматизированный откат не предусмотрен, убедитесь, что у вас есть процедура ручного отката изменений в случае необходимости.

Использование комбинации этих стратегий и методов поможет обеспечить безопасный и надежный процесс деплоя в вашей среде с несколькими серверами и балансировкой трафика Nginx.

## 20. Репозиторий с helm-charts. Открыли ветку. Добавили правку. Делаем MR и получаем конфликт. Как решить конфликт? (Git)

Для разрешения конфликта при слиянии веток, вам потребуется выполнить следующие шаги:

1. **Открыть конфликтный файл:**
   - Найдите файл, в котором возник конфликт при слиянии.
   - Откройте этот файл в текстовом редакторе.

2. **Понять структуру конфликта:**
   - Обычно конфликт отображается в файле с пометками `<<<<<<<`, `=======` и `>>>>>>>`. 
   - `<<<<<<<` обозначает начало изменений из вашей ветки.
   - `=======` разделяет ваш код и код из другой ветки.
   - `>>>>>>>` обозначает конец изменений из другой ветки.

3. **Решить конфликт:**
   - Проанализируйте изменения из обеих веток и решите, какие изменения следует сохранить.
   - Удалите метки `<<<<<<<`, `=======` и `>>>>>>>`, а также ненужные части кода.
   - Оставьте только те изменения, которые необходимо сохранить после слияния.

4. **Добавить изменения и завершить слияние:**
   - После разрешения конфликта сохраните изменения в файле.
   - Добавьте изменения в индекс с помощью команды `git add <file_name>`.
   - Завершите слияние с помощью команды `git merge --continue`.


## 21. Что такое Git Cherry pick? (Git)

https://www.atlassian.com/ru/git/tutorials/cherry-pick#

`git cherry-pick` — это полезная команда, с помощью которой можно выборочно применить коммиты Git к текущей рабочей ветке HEAD. С ее помощью можно выбрать коммит из одной ветки и применить его к другой. Команда `git cherry-pick` — это удобный способ отменить изменения. Например, если коммит попал в ветку по ошибке, вы можете переключиться на нужную ветку и выполнить перенос.

Пользоваться командой `git cherry-pick` удобно, однако это не всегда оптимально. Она может привести к дублированию коммитов, поэтому нередко разработчики предпочитают обычное слияние. Таким образом, можно сказать, что команда `git cherry-pick` — средство эффективное, но узконаправленное.

Пример использования:
Если был обнаружен баг, важно как можно скорее предоставить исправление конечным пользователям. Рассмотрим пример, когда разработчик начинает создавать новую функцию. `В ходе работы обнаруживается существующий баг`, и разработчик создает специальный коммит для его исправления. Этот `коммит можно перенести прямо в основную ветку (main)`, чтобы исправить баг, прежде чем от него пострадают другие пользователи.

## 22. С какими системами/платформами для построения pipelines приходилось работать? (CI/CD)

Jenkins, GitHub Actions, GitLab

## 23. Приходилось ли работать с Ansible, Chef, Terraform? (IaC)

Использование инструментов автоматизации: Для реализации Infrastructure as Code используются инструменты автоматизации, такие как Ansible, Terraform, Chef, Puppet, CloudFormation, Azure Resource Manager и другие. Эти инструменты позволяют развертывать, настраивать и управлять инфраструктурой с использованием кода.

Преимущества подхода Infrastructure as Code включают повышение скорости развертывания инфраструктуры, повышение надежности и согласованности настроек, а также облегчение масштабирования и управления инфраструктурой.

IaC является ключевым элементом DevOps-практик, так как позволяет автоматизировать процессы управления инфраструктурой и интегрировать их в цикл непрерывной поставки (CI/CD).

## 24. Какие плюсы можешь назвать использования infrastructure as code? (IaC)

"Infrastructure as Code" (IaC) - это подход к управлению инфраструктурой IT-систем с использованием программного кода. Вместо ручного настройки серверов, сетей и других инфраструктурных ресурсов, инженеры описывают всю необходимую инфраструктуру в виде кода, который затем может быть автоматически развернут и управляем с использованием инструментов автоматизации.

Основные принципы Infrastructure as Code включают в себя:

1. Декларативное описание инфраструктуры: Инженеры описывают желаемое состояние инфраструктуры (например, какие серверы должны быть развернуты, какие настройки сети нужны и т.д.) в виде декларативного кода, вместо того, чтобы описывать шаги, необходимые для достижения этого состояния.

3. Версионирование и контроль изменений: Код, описывающий инфраструктуру, может быть хранен в системе контроля версий, что позволяет отслеживать изменения, вносимые в инфраструктуру, и возвращаться к предыдущим версиям в случае необходимости.

Преимущества подхода Infrastructure as Code включают повышение скорости развертывания инфраструктуры, повышение надежности и согласованности настроек, а также облегчение масштабирования и управления инфраструктурой.

## 25. Опиши что будет выполняться с task при её выполнении при помощи Ansible. (IaC)

Когда выполняется и при каких условиях?

1. 2 stage
2. Много jobs для каждого stage
3. Через maven в 1ой job запускается приложение.
4. Через maven в 2ой job запускаются тесты.
5. 3я и 4ая jobs выполняются из другого .gitlab-ci при условии push и MR

## 26. Ansible task. Что будет в результате выполнения этих задач? (IaC)

1. Есть 2 таски на скачивание приложения и его установку
2. Скачивание через ссылку. Сохранение в заданную директорию
3. Предоставление прав для директории 755.
4. Установка прилодения из заданной директории.

## 27. Что означает run once aggregate to localhost? (IaC)

- **ansible**: это утилита управления конфигурацией, которая позволяет автоматизировать развертывание, управление и настройку систем.
- **run once**: это опция Ansible, которая указывает, что задача должна быть выполнена только один раз, даже если группа хостов содержит несколько узлов.
- **aggregate**: в данном контексте может означать объединение или сгруппирование результатов выполнения задачи.
- **to localhost**: указывает, что задача должна быть выполнена на локальной машине, на которой запущен Ansible, а не на удаленных хостах.

Команда Ansible означает выполнение задачи только один раз на локальной машине (localhost) и возможно объединение результатов выполнения этой задачи.

## 28. Что такое handler в Ansible и зачем могут понадобиться? (IaC)

Handler в Ansible - это специальный тип задачи, который выполняется только в случае, если другая задача из playbook или роли изменила состояние системы. Handler может быть вызван с помощью модуля `notify` в других задачах, и он выполнится только один раз в конце выполнения playbook, если были изменения, требующие его выполнения.

Handler'ы могут понадобиться в следующих случаях:
1. **Перезапуск сервисов**: Если в процессе выполнения playbook были внесены изменения, требующие перезапуска сервисов, handler может быть использован для выполнения перезапуска только после всех изменений.
2. **Копирование файлов**: Если необходимо скопировать файлы или конфигурации на удаленные хосты после изменений, handler может обеспечить выполнение этого действия только по необходимости.
3. **Уведомления и оповещения**: Handler'ы могут использоваться для отправки уведомлений или оповещений после завершения определенных действий.

Использование handler'ов помогает оптимизировать выполнение playbook'ов, избегая лишних операций и упрощая управление конфигурацией системы.

## 29. Что такое роли в Ansible? (IaC)
sber/education/interview.md - 26. Что такое роли в Ansible?

В Ansible, роли (Roles) представляют собой организационную единицу, которая позволяет группировать связанные задачи, переменные, шаблоны и файлы в единый пакет для более удобного управления конфигурацией и автоматизации. Роли позволяют создавать переиспользуемые компоненты конфигурации, которые могут быть легко применены к различным хостам и инфраструктуре.

Основные компоненты роли в Ansible:

1. Задачи (Tasks): Задачи представляют собой действия, которые нужно выполнить на целевой системе. Например, установка пакетов, настройка сервисов, копирование файлов и т.д.

2. Переменные (Variables): Переменные используются для хранения значений, которые могут быть использованы в задачах и шаблонах. Они позволяют сделать роли более гибкими и настраиваемыми.

3. Шаблоны (Templates): Шаблоны представляют собой файлы с динамическим содержимым, которые могут быть применены к целевой системе. Например, конфигурационные файлы, скрипты и т.д.

4. Файлы (Files): Файлы, которые должны быть скопированы на целевую систему без изменений.

5. Обработчики (Handlers): Обработчики представляют собой действия, которые должны быть выполнены при определенных условиях. Например, перезапуск сервиса после изменения конфигурационного файла.

Роли позволяют создавать модульные и переиспользуемые компоненты конфигурации, которые могут быть легко включены в плейбуки (playbooks) Ansible для автоматизации развертывания и управления инфраструктурой.

## 30. С какими системами мониторинга приходилось работать? (Monitoring)(ОПЫТ)
sber/devices/interview.md - 5. Мониторинг. Какой стек использовал?

1. Использование стека grafana + prometheus + node exporter
2. Использование Instana + Instana agents

## 31. Есть бэк-приложение. HTTP сервер на Spring. Нужно поставить на мониторинг. Какие метрики смотрел бы в 1ую очередь? (Monitoring)

При мониторинге бэкэнд-приложения на Spring HTTP сервере, в первую очередь стоит обратить внимание на следующие ключевые метрики:

1. **Производительность HTTP сервера**:
   - Загрузка CPU и памяти на сервере
   - Количество запросов в секунду
   - Среднее время ответа на запросы

2. **Статусы HTTP запросов**:
   - Коды ответов HTTP (200, 404, 500 и т.д.)
   - Количество успешных и неуспешных запросов

3. **Использование базы данных** (если используется):
   - Загрузка CPU и памяти на сервере базы данных
   - Количество запросов к базе данных
   - Среднее время выполнения запросов к базе данных

4. **Сборщик мусора Java**:
   - Использование памяти Java
   - Частота и длительность сборок мусора

5. **Кэширование**:
   - Попадания и промахи кэша
   - Эффективность кэширования

Для сбора и визуализации этих метрик через Grafana и Prometheus, вам потребуется настроить экспортеры для сбора метрик с HTTP сервера, базы данных (если используется) и других компонентов. Например, для сбора метрик из базы данных можно использовать экспортеры, такие как `Prometheus MySQL Exporter` или `Prometheus PostgreSQL Exporter`.

Эти метрики помогут вам отслеживать производительность и работоспособность вашего бэкэнд-приложения, а также выявлять потенциальные проблемы и улучшать его работу.

## 32. Логирование. Какой стек использовал? (Monitoring)(ОПЫТ)
sber/devices/interview.md - 6. Логирование. Какой стек использовал? 

### Сборка и визуализация логов в Grafana с использованием Loki:

Для логирования на проекте, где уже используется стек мониторинга Grafana + Prometheus, хорошим выбором будет использование Loki в сочетании с Grafana для хранения и визуализации журналов.

Для быстрой настройки логирования докер контейнеров на сервере Linux с использованием Loki и Grafana, вам потребуется выполнить следующие шаги:

1. **Установка и настройка Loki**:
   - Установите Loki на сервере. Можно использовать Docker:
     ```bash
     docker run -d --name loki -p 3100:3100 grafana/loki:latest
     ```
   - Убедитесь, что Loki запущен и доступен по адресу `http://localhost:3100`.

2. **Настройка логирования в докер контейнерах**:
   - Добавьте следующий параметр в запуск контейнера для отправки логов в Loki:
     ```bash
     --log-driver=loki --log-opt loki-url="http://<loki_ip>:3100/loki/api/v1/push"
     ```
   - Перезапустите контейнеры, чтобы применились изменения.

3. **Настройка Grafana для визуализации логов**:
   - Установите Grafana на сервере, если еще не установлено.
   - Добавьте источник данных Loki в Grafana, указав адрес Loki (http://localhost:3100).
   - Создайте панели для визуализации журналов из Loki.

## 33. Каким образом передавались логи в хранилище? Кто отправляет/пишет их? (Loki/Kibana)

Для передачи логов в хранилище, как Loki, так и Kibana, обычно используются агенты логирования или лог-драйверы, которые отправляют или пишут логи в соответствующее хранилище. В случае Loki, контейнеры Docker могут напрямую отправлять логи в Loki, указывая адрес Loki в параметрах запуска контейнера. Для Kibana, обычно используется Elasticsearch как хранилище логов, и логи отправляются в Elasticsearch через лог-драйверы или агенты логирования.

Примеры команд и шагов для поднятия Loki и Kibana в Docker:

1. **Loki**:
   - Запуск контейнера Loki:
     ```bash
     docker run -d --name loki -p 3100:3100 grafana/loki:latest
     ```
   - Убедитесь, что Loki доступен по адресу `http://localhost:3100`.

2. **Kibana** (с Elasticsearch):
   - Запуск контейнера Elasticsearch:
     ```bash
     docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.15.1
     ```
   - Запуск контейнера Kibana:
     ```bash
     docker run -d --name kibana --link elasticsearch:elasticsearch -p 5601:5601 docker.elastic.co/kibana/kibana:7.15.1
     ```
   - Убедитесь, что Kibana доступен по адресу `http://localhost:5601`.

После выполнения этих шагов, Loki и Kibana будут запущены в Docker контейнерах, и вы сможете начать отправлять и визуализировать логи в соответствующих хранилищах. Помните, что для более продуктивного использования, необходимо настроить агенты логирования в ваших контейнерах для отправки логов в Loki или Elasticsearch.

## 34. С какими веб серверами приходилось работать? Какие есть еще кроме nginx?

- Apache HTTP Server
- Microsoft IIS (Internet Information Services)
- LiteSpeed Web Server
- Caddy
- OpenLiteSpeed
- Apache Tomcat (для Java приложений)
- и другие.

Каждый из этих веб-серверов имеет свои особенности и подходит для разных типов приложений и сценариев использования.

## 35. Nginx у нас на сервере как балансировщик нагрузки. Есть 4 бэк сервера, на которых развёрнуто одинаковое приложение. Какие есть способы балансировки запросов между бэк серверами?

Для балансировки запросов между бэкенд серверами с помощью Nginx в качестве балансировщика нагрузки, можно использовать различные методы балансировки, такие как round-robin, least connections, ip-hash и другие.

Пример команд и шагов для настройки балансировки запросов с использованием Nginx:

- Установите Nginx на сервере, если он еще не установлен.
- Отредактируйте конфигурационный файл Nginx (обычно располагается в `/etc/nginx/nginx.conf` или `/etc/nginx/sites-available/default`) и добавьте блок для балансировки нагрузки:

```nginx
http {
    upstream backend {
        server backend1:80;
        server backend2:80;
        server backend3:80;
        server backend4:80;
    }

    server {
        listen 80;

        location / {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}
```

- Перезапустите Nginx для применения изменений:

```bash
sudo systemctl restart nginx
```

После выполнения этих шагов, Nginx будет балансировать запросы между четырьмя бэкенд серверами, на которых развернуто одинаковое приложение. Вы можете настроить и другие параметры балансировки в соответствии с вашими потребностями.

## 36. Приходилось ли настраивать CORS (Cross-Origin Resource Sharing)? Что это?

CORS (Cross-Origin Resource Sharing) - это механизм, который позволяет веб-странице запрашивать ресурсы с другого источника (домена, протокола или порта), отличного от источника, с которого была загружена сама страница. Это важная мера безопасности, которая помогает предотвратить атаки с использованием скриптов на стороне клиента.

Пример настройки CORS в Nginx:

1. Откройте конфигурационный файл Nginx (обычно располагается в `/etc/nginx/nginx.conf` или `/etc/nginx/sites-available/default`).

2. Добавьте следующие строки для разрешения CORS для всех ресурсов:

```nginx
server {
    listen 80;
    server_name example.com;

    location / {
        add_header 'Access-Control-Allow-Origin' '*';
        add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
        add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range';
    }
}
```

3. Перезапустите Nginx для применения изменений:

```bash
sudo systemctl restart nginx
```

Теперь сервер Nginx будет отправлять заголовки CORS в ответ на запросы, разрешая доступ к ресурсам с других источников.

## 37. Какой-нибудь http заголовок сможешь назвать, который постоянно используется? Именно в протоколе - a header

Несколько примеров HTTP заголовков, которые часто используются:

Заголовок `('Content-Type', 'application/json')` используется для указания, что контент запроса или ответа является JSON-данными. Он помогает клиенту и серверу правильно интерпретировать передаваемые данные.

- `Content-Type`: указывает тип контента в теле запроса или ответа, например, `application/json`.
- `Authorization`: содержит информацию для аутентификации пользователя, обычно используется для передачи токена доступа.
- `User-Agent`: содержит информацию о браузере или приложении, отправляющем запрос.
- `Accept`: указывает, какие типы контента клиент может принять от сервера.

Пример создания заголовков в JS коде:

```javascript
const headers = new Headers();
headers.append('Content-Type', 'application/json');
headers.append('Authorization', 'Bearer token123');

fetch('https://api.example.com/data', {
    method: 'GET',
    headers: headers
})
.then(response => {
    // Обработка ответа
})
.catch(error => {
    // Обработка ошибки
});
```

В этом примере создаются и добавляются HTTP заголовки `Content-Type` и `Authorization` к запросу, отправляемому с помощью функции `fetch` в JavaScript.

## 38. С какими БД работал? Какие задачи были связанные с БД? (БД)

1) Реляционные (например, MySQL, PostgreSQL), NoSQL (например, MongoDB, Redis) и облачные базы данных (например, Amazon RDS, Google Cloud Firestore).

Примеры часто используемых баз данных и их отличия:

- MySQL vs PostgreSQL:
  - MySQL: широко распространенная реляционная база данных, хорошо подходит для простых приложений с небольшим объемом данных. Имеет хорошую производительность при чтении данных.
  - PostgreSQL: также реляционная база данных, но более мощная и расширяемая. Поддерживает более сложные запросы и транзакции, что делает ее хорошим выбором для более сложных приложений.

- MongoDB vs Redis:
  - MongoDB: NoSQL база данных, хранящая данные в формате JSON-подобных документов. Хорошо подходит для приложений с гибкой схемой данных и потребностью в масштабируемости.
  - Redis: NoSQL база данных, работающая в оперативной памяти. Используется для кэширования данных и обработки высоконагруженных операций, таких как счетчики и сессии.

2) Задачи, связанные с базами данных:

- Установка и настройка баз данных на серверах.
- Резервное копирование и восстановление данных.
- Масштабирование и оптимизация производительности баз данных.
- Мониторинг и управление ресурсами баз данных.
- Автоматизация процессов управления базами данных с помощью инструментов DevOps, таких как Ansible, Terraform, Docker.

## 39. Основы управления и мониторинга баз данных. Основы NoSQL баз данных и их отличия. Инструменты автоматизации. (БД)

1) **Основы NoSQL баз данных и их отличия от реляционных баз данных:**

NoSQL базы данных отличаются от реляционных тем, что они не используют традиционную таблицу с рядами и столбцами для хранения данных. Вместо этого они используют различные модели данных, такие как документы, ключ-значение, столбцы или графы. Основные отличия включают:

- **Гибкая схема данных:** NoSQL базы данных позволяют хранить данные без строгой схемы, что упрощает добавление новых полей или изменение структуры данных без необходимости изменения всей базы данных.

- **Горизонтальное масштабирование:** NoSQL базы данных легче масштабируются горизонтально, что означает добавление новых узлов для увеличения производительности и хранения больших объемов данных.

Пример отличия: 
В реляционной базе данных для хранения информации о пользователях и их заказах может потребоваться несколько таблиц (например, таблица пользователей и таблица заказов), связанных внешними ключами. В то время как в NoSQL базе данных, такой же набор данных может быть храниться в виде документов, где каждый документ содержит информацию о пользователе и его заказах вместе.

2) **Основы управления и мониторинга баз данных:**

Мониторинг баз данных включает в себя отслеживание производительности, доступности, использования ресурсов и обнаружение проблем. Пример мониторинга базы данных может включать:

- Отслеживание запросов и времени выполнения.
- Мониторинг использования памяти, CPU и дискового пространства.
- Оповещения о сбоях или недоступности базы данных.
- Анализ долгих или заблокированных запросов.

Для мониторинга базы данных могут использоваться инструменты, такие как Prometheus, Grafana, Nagios, Zabbix и многие другие.

3) **Инструменты автоматизации и оркестрации для работы с базами данных в инфраструктуре:**

Пример автоматизации работы с базами данных может включать использование инструментов, таких как Ansible, Terraform, Docker и Kubernetes. Например, с помощью Ansible можно автоматизировать установку и настройку баз данных на серверах, с Terraform можно создавать и управлять инфраструктурой, а с помощью Docker и Kubernetes можно упаковывать и развертывать базы данных в контейнерах.

Небольшой пример автоматизации с использованием Ansible:
```yaml
- name: Установка PostgreSQL
  hosts: database_servers
  tasks:
    - name: Установка PostgreSQL
      apt:
        name: postgresql
        state: present
```

В этом примере с помощью Ansible выполняется установка PostgreSQL на серверах, указанных в группе `database_servers`.

## 40. Как работает репликация в PostgreSQL и MySQL? Каких видов бывает и чем отличается?

**Репликация в PostgreSQL:**

Репликация в PostgreSQL - это процесс создания и поддержания точной копии базы данных (мастера) на одном или нескольких других серверах (реплики) для повышения отказоустойчивости, масштабируемости и увеличения доступности данных. Репликация в PostgreSQL может быть настроена с использованием различных методов:

1) **Логическая репликация:** В этом методе изменения данных на мастере записываются в специальные журналы, которые затем передаются и применяются на репликах. Этот метод позволяет более гибко настраивать репликацию и переносить только определенные данные.

2) **Физическая репликация:** В этом методе данные копируются байт в байт с мастера на реплики. Этот метод более эффективен с точки зрения производительности, так как данные передаются в бинарном формате.

3) **Смешанная репликация:** Комбинация логической и физической репликации, позволяющая достичь оптимального баланса между гибкостью и производительностью.

**Репликация в MySQL:**

В MySQL также существует несколько видов репликации:

1) **Мастер-мастер репликация:** В этом случае оба сервера могут одновременно принимать записи и реплицировать их друг на друга. Это позволяет балансировать нагрузку и обеспечивать отказоустойчивость.

2) **Мастер-репликация:** В этом случае один сервер (мастер) принимает записи, а другие сервера (реплики) получают их и воспроизводят. Этот метод обеспечивает масштабируемость и отказоустойчивость.

3) **Цепочка репликации:** В этом методе репликация осуществляется через цепочку серверов, где каждый следующий сервер является репликой предыдущего. Это позволяет создавать сложные схемы репликации для улучшения производительности и отказоустойчивости.

**Отличия:**

- PostgreSQL поддерживает как логическую, так и физическую репликацию, в то время как MySQL имеет более широкий выбор методов репликации, включая мастер-мастер и цепочку репликации.
- В PostgreSQL логическая репликация позволяет более гелко настраивать репликацию и переносить только определенные данные, в то время как в MySQL мастер-мастер репликация обеспечивает балансировку нагрузки между серверами.
- Оба СУБД обеспечивают высокую отказоустойчивость и масштабируемость с помощью репликации, но методы их реализации могут различаться.

## 41. В чем разница между виртуализацией и контейнеризацией (как подходов к деплою приложений). Где преимущества 1го и другого и их недостатки?



## 42. 



## 43. 



## 44. 





## Продолжить (ИТ1 тех собес 1/2) с 01:06:10