# Список вопросов:

## Собеседование с IT-One:

-----------------------

# Вопросы из записи в iCloud (ИТ1 тех собес 1/2):

# ОПЫТ:

## 1. Есть что-то такое что запомнилось как большой успех? Не успех работы, а что приятно лично вспоминать. (ОПЫТ)
https://www.linkedin.com/in/vitalylobachev/details/experience/ - пример опыта работа Лабочева Виталия

**Достижения в работе**:

1. Рефакторинг и приведение к единому стандарту инфраструктуры команд Банка что позволяет экономить время на конфигурацию сервера/сервисов.
2. Документация всей проделанной работы на досках в Jira, в Confluence, в пайплайнах, скриптах и конфигах что позволяет экономить своё время и сотрудников на изучение инфры и обучение сотрудников.
3. Настройка мониторинга для всех команд (серверов, устройств, контейнеров, сервисов и бд)
4. Настройка CI/CD для тестирования, сборок и доставки кода для разных команд Банка.
5. Автоматизация нотификаций, очистки логов/данных на серверах, создания УЗ, регистрации раннеров, выпуска сертификатов.
6. Траблшутинг проблем, сетевых доступов и пайплайнов.

## 2. Факапы за время работы DevOps? (ОПЫТ)

1. Дали чужой PROD сервер с рабочим allure-server и запущенными приложениями. Не 1 сервер - 1 сервис, а прод сервер с 30 запущенными сервисами и регулярно запускающимися авто-тестами в несколько потоков.
    1. Согласился разобраться с проблемами на проблемном сервере.
    2. Не изучил всю архитектуру и не сразу нашел корень проблемы.
    3. Ко мне пришли с проблемой что отчеты перестали писаться на диск. Нехватка места или проблема с allure-server.
    4. На сервере были внесены изменения в конфигурации сотрудником и был ребут сервака.
    5. После ребута отлетели mount диски и я ЭТО не проверил/не нашел сразу.
    6. Отчеты стали писаться на другой диск. 
    7. Забилась /root директория с др диском. 
    8. Очистка памяти не помогала.
    9. Приложения падали с ошибкой из-за нехватки места.
    10. Не сразу нашел ссылки на директории, в которые писались логи. (Символические ссылки)
2. Потратил уйму времени на локализацию главной проблемы что диск был отмонтирован и повлёк за собой пачку проблем.

## 3. Нужно зайти на сервер и посмотреть потребление ресурсов. Процессор/Память/Диск/Сеть. Какими командами? (Linux)

Просмотр потребления ресурсов (процессор, память, диск, сеть) на сервере Linux:

1. `top`, `htop` - Онлайн просмотр MEMORY и CPU, NI (приоритет)

2. `free -h` - Просмотр использования памяти. 
    1. `lscpu` - информация о процессах
    2. `ps aux` - инфо о процессах (PID/USER/MEM/TIME/CPU)

3. `df -h`, `df -T`, `df -i` - Просмотр использования диска
    1. `du -axh --max-depth=1 /var` - folder used memory
    2. `tune2fs -l /dev/mapper/vg01-lv_var` - инфо по диску
    3. `ls -ltr | tail -1` - самый свежий файл
        1. `ls -lt | tail -1` - самый старый файл

4. `iftop`, `ip -s link` - Просмотр использования сети

5. `vgs` - volume groups

6. `iptables` - утилита для настройки правил брандмауэра в Linux. С помощью `iptables` можно управлять трафиком сетевых пакетов, определять, какие пакеты разрешены или блокированы, настраивать NAT (Network Address Translation), а также многое другое.

    Ключевые моменты об `iptables` (https://habr.com/ru/articles/747616/):

    1. **Таблицы**: `iptables` имеет различные таблицы, такие как `filter`, `nat`, `mangle`, `raw`, `security`. Каждая таблица используется для определенных целей, например, фильтрации пакетов (`filter`), NAT (`nat`), изменения заголовков пакетов (`mangle`).

    2. **Цепочки**: В рамках каждой таблицы существуют различные цепочки, такие как `INPUT`, `OUTPUT`, `FORWARD`. Цепочки определяют, куда направляются пакеты и какие правила применяются к ним.

    3. **Правила**: Правила `iptables` определяют, что делать с пакетами, которые проходят через брандмауэр. Правила могут разрешать, блокировать, перенаправлять или изменять пакеты в соответствии с заданными условиями.

    Через `iptables` можно просматривать текущие правила брандмауэра, смотреть статистику использования правил, добавлять новые правила, удалять и изменять существующие правила и т.д. 

    Например:

    1. `iptables -t nat -L` используется для просмотра правил NAT в таблице `nat`.
    2. `iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 8080` - для редиректа трафика с `--dport 80` до `--to-port 8080`
    3. `iptables -A INPUT -p tcp --dport 22 -m state --state NEW -m limit --limit 3/min -j ACCEPT` - для ограничения скорости
    4. `iptables -A INPUT -j LOG --log-prefix "Dropped Packet: " iptables -A INPUT -j DROP` - логирование всех отброшенных пакетов

## 4. Чем отличается системное от пользовательского времени (процессорное)? (Linux)

1. Пользовательское время — это время, затраченное процессором на выполнение команд, заданных пользовательской программой. 
2. Системное время — это время, затраченное на выполнение операционной системой и различными системными службами. 
3. Процессорное время может быть разделено между несколькими задачами или программами.

## 5. В Allure-server - ошибка: "No space left on device" и путь. df -h показывает что место есть. В чем проблема? (Linux)

1. Закончились Inodes (мета данные).
2. Проверю кол-во свободных инод на диске `df -i` или `df -ih`
3. Нужно увеличить размер диска что повлечет увеличение свободных inodes.
    1. Либо изменить файловую систему на более подходящую под задачи сервиса/сервера.
    2. `df -T` - fs Type: `ext4` (улучшенная версия ext3), `btrfs`, `XFS`, `FAT32`, `NTFS`:
        1. `ext4` - max размер раздела: 50-100тб, max размер файла: 16тб, max кол-во файлов - 4млрд
        2. `XFS` - max размер раздела: 8 экзабайт, max размер файла: 8 экзабайт, max кол-во файлов - 2 в 64 степени

## 6. Как потюнить Файловую систему? Какой командой её можно улучшить? (Linux)

Настройка и оптимизация файловой системы в Linux может повысить производительность и эффективность работы сервера. Одной из команд, которая может помочь улучшить файловую систему, является `tune2fs`.

`Tune2fs` - это утилита для настройки параметров файловых систем ext2/ext3/ext4. Некоторые параметры, которые можно настроить с помощью `tune2fs`:

1. **Интервал проверки файловой системы**: Можно изменить интервал проверки файловой системы на наличие ошибок при помощи опции `-c` (по количеству монтирований) или `-i` (по времени).

2. **Интервал записи журнала**: Можно изменить интервал записи журнала файловой системы с помощью опции `-J`.

3. **Размер журнала**: Можно изменить размер журнала файловой системы с помощью опции `-j`.

4. **Метка файловой системы**: Можно установить метку файловой системы с помощью опции `-L`.

5. **Максимальное количество монтирований**: Можно установить максимальное количество монтирований перед проверкой файловой системы с помощью опции `-C`.

Примеры использования `tune2fs`:

- Установить интервал проверки файловой системы на 30 дней:
```bash
sudo tune2fs -i 30d /dev/sdX
```

- Установить метку файловой системы:
```bash
sudo tune2fs -L "mylabel" /dev/sdX
```

## 7. Как поднять приоритет выполнения процесса на процессоре? (Linux)

Управлять приоритетом выполнения процессов с помощью утилиты `nice` или команды `renice`. 
Приоритет процесса определяет, как часто процесс получает доступ к процессорным ресурсам. Чем ниже значение приоритета, тем выше приоритет у процесса.

1. **Установка приоритета с помощью `nice`**:
   - Команда `nice` используется для запуска процесса с измененным приоритетом. Чем больше значение приоритета, тем ниже приоритет у процесса.
   - Пример установки приоритета процесса на 10: `nice -n 10 command`
   - В данном примере `command` - это команда, для которой вы хотите изменить приоритет.

2. **Изменение приоритета с помощью `renice`**:
   - Команда `renice` позволяет изменить приоритет уже запущенного процесса.
   - Пример изменения приоритета процесса с PID 123 на 5: `renice 5 -p 123`
   - В данном примере `123` - это идентификатор процесса.

3. **Просмотр текущего приоритета процессов**:
   - Для просмотра текущего приоритета процессов можно использовать команду `top` или `htop`. Приоритет отображается в столбце `NI` (nice value).

Важно помнить, что установка слишком высокого приоритета для процесса может привести к замедлению работы других процессов на системе. Рекомендуется быть осторожным при изменении приоритетов процессов и учитывать потребности других процессов на сервере.

## 8. Символические ссылки и жесткие ссылки. В чем разница? (Linux)

Символические ссылки (`symbolic links`) и жесткие ссылки (`hard links`) - это два способа создания ссылок на файлы в UNIX-подобных операционных системах, таких как Linux. Они имеют разные особенности и применения:

1. **Жесткие ссылки (hard links)**: `ln file1.txt hardlink.txt`
   - Жесткая ссылка - это второе (или более) имя файла, которое указывает на те же данные на диске, что и первое имя.
   - Жесткие ссылки работают только в пределах одной файловой системы.
   - Удаление исходного файла не влияет на жесткие ссылки, так как они указывают на те же данные на диске.
   - Жесткие ссылки не могут быть созданы для директорий.
   - Изменения в одном файле отразятся во всех его жестких ссылках, так как все они указывают на одни и те же данные.
   - Имеет одинаковый id c оригиналом

2. **Символические ссылки (symbolic links)**: `ln -s file1.txt softlink.txt`
   - Символическая ссылка - это специальный файл, который содержит путь к другому файлу или директории.
   - Символические ссылки могут пересекать границы файловых систем и могут указывать на файлы, которые еще не существуют.
   - Если исходный файл удален, символическая ссылка становится битой и не может быть использована.
   - Символические ссылки могут быть созданы для директорий.
   - Изменения в исходном файле не влияют на символическую ссылку, так как она просто содержит путь к файлу.
   - Имеет разные id c оригиналом и является ссылкой (другой тип файла и другой id)

В общем, жесткие ссылки обеспечивают более непосредственное соединение между файлами, в то время как символические ссылки предоставляют более гибкую возможность ссылаться на файлы. Каждый тип ссылок имеет свои особенности и применения, и выбор между ними зависит от конкретной задачи.

`ls -l` - для просмотра информации о ссылках на файлы в столбце links

## 9. Как ограничить процесс по потребляемой оперативной памяти? (Linux)

1. Ограничение потребления оперативной памяти контейнера `gitlab-runner-bank2` в 250MB:

    **Шаг 1:** Найти ID контейнера `gitlab-runner-bank2` - `docker ps`

    **Шаг 2:** Команда `docker stats gitlab-runner-bank2` чтобы увидеть текущее потребление оперативной памяти

    **Шаг 3:** Установить ограничение на потребление оперативной памяти контейнера `docker update --memory 250m gitlab-runner-bank2`


2. Создание процесса в Linux и установки ограничения на его потребление оперативной памяти в 250MB:

    **Шаг 1:** Файл `light_process.sh` для создания процесса:
    ```bash
    #!/bin/bash

    while true
    do
        echo "Light process is running..."
        sleep 1000
    done
    ```

    **Шаг 2**: Сделайте скрипт исполняемым: `chmod +x light_process.sh`

    **Шаг 3**: Запустите скрипт light_process.sh в фоновом режиме: `./light_process.sh &`

    **Шаг 4**: Найдите PID (идентификатор процесса) запущенного процесса, используя команду ps: `ps aux | grep light_process.sh`

    **Шаг 5**: Установите ограничение на потребление оперативной памяти для процесса, используя утилиту cgroups. Создайте cgroup с именем `memory_limit` и установите ограничение в 250MB:
    ```bash
    sudo mkdir /sys/fs/cgroup/memory/memory_limit
    echo 250M > /sys/fs/cgroup/memory/memory_limit/memory.limit_in_bytes
    echo $$ > /sys/fs/cgroup/memory/memory_limit/tasks
    ```

    **Шаг 6**: Посмотреть текущий лимит и после его обновления:
    ```bash
    cat /sys/fs/cgroup/memory/memory_limit/memory.limit_in_bytes 
    9223372036854771712

    echo 250M > /sys/fs/cgroup/memory/memory_limit/memory.limit_in_bytes

    cat /sys/fs/cgroup/memory/memory_limit/memory.limit_in_bytes 
    262144000
    ```
    **Шаг 7**: Добавить PID процесса в созданную группу:
    ```bash
    echo 3327922 > /sys/fs/cgroup/memory/process1/tasks
    cat /sys/fs/cgroup/memory/memory_limit/tasks
    3327922
    3328466
    3329874
    ```

## 10. Что такое DNS? (DNS)
Ответ есть в sber/education/interview.md

1. **Как работает DNS**:
   - **DNS (Domain Name System)** - это система, которая переводит доменные имена в IP-адреса и наоборот. Основные принципы работы DNS:
     - Когда вы вводите доменное имя в веб-браузере, ваш компьютер отправляет запрос DNS-серверу для получения соответствующего IP-адреса.
     - DNS-серверы содержат базы данных с записями DNS, которые соответствуют доменным именам IP-адресам.
     - DNS использует иерархическую структуру доменных имен, где домены разделены точками (например, sregistry.mts.ru).
     - Различные типы записей DNS включают A (IPv4-адрес), AAAA (IPv6-адрес), CNAME (каноническое имя), MX (почтовый сервер) и другие.

2. **Как настроить DNS**:
   - Для настройки DNS необходимо уметь работать с DNS-серверами, добавлять и изменять записи DNS, управлять зонами и кэшированием. Некоторые шаги настройки DNS:
     - Настройка DNS-сервера (например, BIND, Microsoft DNS).
     - Добавление и изменение записей DNS (A, CNAME, MX и т. д.) для привязки доменных имен к IP-адресам.
     - Управление зонами DNS, которые определяют, какие домены и поддомены обслуживает DNS-сервер.
     - Настройка кэширования DNS для ускорения процесса разрешения доменных имен.

3. **DNS безопасность**:
   - Для обеспечения безопасности DNS необходимо защищаться от DDoS-атак, DNS-подделок и других угроз безопасности. Некоторые методы защиты:
     - Использование DNSSEC (DNS Security Extensions) для обеспечения целостности и аутентичности данных DNS.
     - Настройка файрвола для блокировки нежелательных DNS-запросов и защиты от DDoS-атак.
     - Мониторинг и аудит DNS-трафика для обнаружения аномалий и подозрительной активности.
     - Регулярное обновление и усиление конфигурации DNS-серверов для предотвращения уязвимостей.

Чаще всего DevOps инженеры используют специализированные DNS-серверы, такие как BIND, PowerDNS, dnsmasq или другие, для управления DNS-зонами и обеспечения доступности и надежности DNS-сервиса.

Пример использования DNS на Ubuntu сервере Linux:
1. Установка DNS-сервера BIND:
```
sudo apt update
sudo apt install bind9
```

2. Настройка зоны DNS в файле `/etc/bind/named.conf.local`:
```bash
zone "sregistry.mts.ru" {
    type master;
    file "/etc/bind/zones/sregistry.mts.ru.zone";
};
```

3. Создание файла зоны `/etc/bind/zones/sregistry.mts.ru.zone` и добавление записей:
```bash
$TTL    604800
@       IN      SOA     ns1.sregistry.mts.ru. admin.sregistry.mts.ru. (
                2022010101  ; Serial
                604800      ; Refresh
                86400       ; Retry
                2419200     ; Expire
                604800 )    ; Negative Cache TTL
;
@       IN      NS      ns1.sregistry.mts.ru.
@       IN      A       192.168.1.10
www     IN      A       192.168.1.20
```

4. Перезапуск DNS-сервера для применения изменений: `sudo systemctl restart bind9`

Теперь сервер Ubuntu Linux будет использовать настроенный DNS-сервер для разрешения доменных имен в IP-адреса.

## 11. Какие бывают типы записей в DNS? (DNS)

Дополнительно к упомянутым типам записей DNS (A, AAAA, CNAME, MX), существуют и другие распространенные типы записей, вот некоторые из них:

1. **NS (Name Server)** - указывает на авторитетные DNS-серверы для конкретной зоны.
2. **PTR (Pointer)** - используется для обратного маппинга IP-адресов на доменные имена (reverse DNS lookup).
3. **TXT** - позволяет добавлять произвольный текстовый комментарий к доменному имени, часто используется для SPF (Sender Policy Framework) записей для электронной почты.
4. **SRV (Service)** - определяет местоположение службы в сети, таких как серверы электронной почты или VoIP.
5. **SOA (Start of Authority)** - содержит информацию об авторитетности зоны и параметры обслуживания.
6. **CAA (Certification Authority Authorization)** - определяет, какие сертификационные органы имеют право выдавать SSL-сертификаты для данного домена.
7. **SPF (Sender Policy Framework)** - определяет список IP-адресов, которые авторизованы отправлять электронную почту от имени домена.

## 12. Приведи примеры каждого типа записи. (DNS)

Примеры записей для типов A, AAAA, CNAME и MX:

1. **A (IPv4-адрес)**: 
   - Пример записи A: 
     ```
     sregistry.mts.ru. IN A 192.0.2.1
     ```
   В данном примере домен sregistry.mts.ru связан с IPv4-адресом 192.0.2.1.

2. **AAAA (IPv6-адрес)**: 
   - Пример записи AAAA: 
     ```
     sregistry.mts.ru. IN AAAA 2001:0db8:85a3:0000:0000:8a2e:0370:7334
     ```
   В данном примере домен sregistry.mts.ru связан с IPv6-адресом 2001:0db8:85a3:0000:0000:8a2e:0370:7334.

3. **CNAME (каноническое имя)**: 
   - Пример записи CNAME: 
     ```
     www.sregistry.mts.ru. IN CNAME sregistry.mts.ru.
     ```
   В данном примере поддомен www.sregistry.mts.ru перенаправляется на домен sregistry.mts.ru.

4. **MX (почтовый сервер)**: 
   - Пример записи MX: 
     ```
     sregistry.mts.ru. IN MX 10 mail.sregistry.mts.ru.
     ```
   В данном примере почтовые сообщения для домена sregistry.mts.ru будут отправляться на почтовый сервер mail.sregistry.mts.ru с приоритетом 10.

Каждая запись имеет свой синтаксис и структуру, которая определяет связь между доменным именем и соответствующими IP-адресами или другими серверами.

## 13. Команды и утилиты чтобы опросить DNS сервер. (DNS)

Существует несколько утилит и команд, которые можно использовать для опроса DNS-сервера и получения информации о доменных записях. Некоторые из наиболее распространенных утилит включают в себя `nslookup`, `dig`, `host` и `nsq`.

1. **nslookup**:
   - Пример использования:
     ```
     nslookup sregistry.mts.ru
     Name: sregistry.mts.ru
     Address: 11.215.144.1
     ```
   Эта команда позволяет выполнить DNS-запрос для домена sregistry.mts.ru и вывести информацию о соответствующих записях.

2. **host**:
   - Пример использования:
     ```bash
     host sregistry.mts.ru
     sregistry.mts.ru has address 11.215.144.1

     host -t MX mail.mtsbank.ru
     mail.mtsbank.ru is an alias for adns.mail.mtsbank.ru.
     ```
   Эта команда позволяет выполнить DNS-запрос для типа записи MX (почтовый сервер) для домена sregistry.mts.ru и вывести информацию о почтовом сервере.

3. **dig** (Domain Information Groper):
   - Пример использования:
     ```bash
     dig AAAA sregistry.mts.ru

     ; <<>> DiG 9.16.48-Ubuntu <<>> AAAA sregistry.mts.ru
     ;; global options: +cmd
     ;; Got answer:
     ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 60238
     ;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 1

     ;; OPT PSEUDOSECTION:
     ; EDNS: version: 0, flags:; udp: 65494
     ;; QUESTION SECTION:
     ;sregistry.mts.ru.              IN      AAAA

     ;; Query time: 0 msec
     ;; SERVER: 127.0.0.53#53(127.0.0.53)
     ;; WHEN: Thu Feb 29 21:08:50 MSK 2024
     ;; MSG SIZE  rcvd: 45
     ```
   1. NOERROR - это означает, что запрос был выполнен успешно и не возникло ошибок.
   2. Ответ: ANSWER: 0 - это означает, что в ответе на запрос не было найдено записей AAAA (IPv6 адресов) для домена sregistry.mts.ru.
   3. Сервер DNS: SERVER: 127.0.0.53#53(127.0.0.53) - запрос был отправлен на локальный DNS сервер с IP-адресом 127.0.0.53.
   4. Время выполнения запроса: Query time: 0 msec - запрос был выполнен за очень короткое время.
   5. Из данного вывода следует, что для домена sregistry.mts.ru отсутствуют записи AAAA (IPv6 адресов). 

Эти утилиты и команды могут быть использованы для проверки доступности DNS-сервера, получения информации о доменных записях, а также для диагностики и анализа проблем с DNS.

## 14. У нас есть директория, у неё права 755. Что это обозначает? (Linux)

Права 755:
1. (4+2+1=7) - владелец файла имеет права на чтение, запись и выполнение
2. (4+0+1=5) - группа и остальные пользователи имеют права только на чтение и выполнение

## 15. Что означает "Выполнение" для директории? (Linux)

1. Право на чтение позволяет пользователю получить список содержимого папки. 
2. Право на запись позволяет создавать и удалять файлы в этой папке. 
3. Право на исполнение разрешает перейти в эту папку:
    1. `cd /Users/andreyshabunov/PhpstormProjects/devops-interviews` - перейти в директорию
    2. `ls -l /Users/andreyshabunov/PhpstormProjects/devops-interviews` - список файлов директории

## 16. У нас есть директория, у неё права 700. Нужно не меняя владельца и права добавить доступ кому-то для работы с этой директорией. Как это сделать? (Linux)

Утилита `setfacl` позволяет управлять расширенными списками контроля доступа (ACL) в Linux:

1. Установить ACL для директории, чтобы включить расширенные списки контроля доступа:
   ```
   setfacl -m u:pberyozkin_adm:rwx /home/ashabunov_adm/test
   ```
   Добавить доступ для pberyozkin_adm

2. Посмотреть текущие ACL для директории:
   ```
   getfacl /home/ashabunov_adm/test/
   ```

3. Вывод команды `getfacl /home/ashabunov_adm/test/`:
    ```
    getfacl: Removing leading '/' from absolute path names
    # file: home/ashabunov_adm/test/
    # owner: ashabunov_adm
    # group: docker
    user::rwx
    user:pberyozkin_adm:rwx         #effective:---
    group::r-x                      #effective:---
    mask::---
    other::---
    ```

## 17. AppArmor и SELinux профиль. Приходилось ли дебажить и настраивать? (Linux)

`AppArmor` и `SELinux` - это две различные системы обязательного контроля доступа в Linux, которые обеспечивают дополнительный уровень безопасности для системы.

1. `AppArmor` (Application Armor) - это система контроля доступа, которая ограничивает возможности программ, устанавливая правила для их исполнения. AppArmor работает на уровне приложений и позволяет определить, какие ресурсы и операции приложение может использовать. Для настройки профилей безопасности в AppArmor используется специальный язык профилей.

2. `SELinux` (Security-Enhanced Linux) - это модуль ядра Linux, который предоставляет механизм обязательного контроля доступа на основе меток безопасности. SELinux управляет доступом к файлам, процессам, портам и другим ресурсам, определяя политики безопасности для различных объектов в системе.

Настройка профилей дебага и настройка в контексте AppArmor и SELinux может включать в себя определение правил доступа для конкретных приложений или сервисов, управление метками безопасности, а также настройку аудита и журналирования для отслеживания событий безопасности.

Обе системы обеспечивают возможность создания профилей безопасности для различных приложений и сервисов, что позволяет усилить защиту системы от различных угроз.

## 18. Что такое CI/CD? (CI/CD)
sber/education/interview.md - 29. Идеальный пайплайн в CI/CD. Какие должны быть шаги?

CI/CD (Continuous Integration/Continuous Delivery) - это практика разработки программного обеспечения, которая объединяет непрерывную интеграцию (CI) и непрерывную поставку (CD) для автоматизации процесса разработки, тестирования и развертывания приложений.

1. **Continuous Integration (непрерывная интеграция)** - это практика, при которой разработчики регулярно объединяют свой код в общий репозиторий, после чего автоматически запускаются сборка и тестирование приложения. Это позволяет выявлять и исправлять конфликты интеграции и ошибки в коде на ранних этапах разработки.

2. **Continuous Delivery (непрерывная поставка)** - это практика, при которой каждое изменение кода, прошедшее успешные тесты в процессе CI, автоматически готово к развертыванию в производственную среду. Это позволяет ускорить процесс доставки новых функций и обновлений пользователям.

CI/CD позволяет командам разработки создавать, тестировать и разворачивать программное обеспечение быстрее и эффективнее, уменьшая риски и повышая качество продукта. Автоматизация процессов CI/CD помогает улучшить скорость разработки, улучшить сотрудничество в команде и упростить управление развертыванием приложений.

## 19. Выкатка на прод. Бэк деплоится на ВМ или bare metal (20 шт). Nginx балансирует запросы клиентов на бэк. Какие есть способы/стратегии деплоя в такую среду чтобы при наличии ошибки отследить/откатить? Стратегии постепенного деплоя.

Для деплоя в среду с несколькими серверами, где бэкенд деплоится на виртуальные машины или физические серверы (bare metal), и запросы балансируются Nginx, важно иметь стратегии деплоя, которые позволяют отслеживать ошибки и в случае необходимости откатывать изменения. Ниже приведены некоторые распространенные стратегии деплоя и методы обработки ошибок:

1. **Стратегии деплоя:**

   - **Blue-Green деплоймент:** При использовании этой стратегии создаются два окружения (Blue и Green). На одном из них работает текущая версия приложения (например, Blue), а на другом развертывается новая версия (Green). После успешного тестирования новой версии, балансировщик трафика переключается на новое окружение. Это позволяет быстро откатиться к предыдущей версии в случае проблем.

   - **Canary деплоймент:** При использовании этой стратегии новая версия приложения постепенно внедряется в производственную среду путем направления только части трафика на нее. Это позволяет постепенно оценивать стабильность новой версии и быстро реагировать на возможные проблемы.

2. **Обработка ошибок и откат изменений:**

   - **Мониторинг и логирование:** Важно настроить мониторинг и логирование на серверах и балансировщике, чтобы быстро обнаруживать ошибки после деплоя.

   - **Автоматизированный откат:** Разработайте процедуру автоматизированного отката изменений в случае обнаружения критических ошибок. Это может включать в себя использование инструментов для управления конфигурациями или CI/CD платформ.

   - **Тестирование перед деплоем:** Проведите тщательное тестирование новой версии приложения перед деплоем в продакшн, чтобы минимизировать риск возникновения ошибок.

   - **Ручной откат:** Если автоматизированный откат не предусмотрен, убедитесь, что у вас есть процедура ручного отката изменений в случае необходимости.

Использование комбинации этих стратегий и методов поможет обеспечить безопасный и надежный процесс деплоя в вашей среде с несколькими серверами и балансировкой трафика Nginx.

## 20. Репозиторий с helm-charts. Открыли ветку. Добавили правку. Делаем MR и получаем конфликт. Как решить конфликт? (Git)

Для разрешения конфликта при слиянии веток, вам потребуется выполнить следующие шаги:

1. **Открыть конфликтный файл:**
   - Найдите файл, в котором возник конфликт при слиянии.
   - Откройте этот файл в текстовом редакторе.

2. **Понять структуру конфликта:**
   - Обычно конфликт отображается в файле с пометками `<<<<<<<`, `=======` и `>>>>>>>`. 
   - `<<<<<<<` обозначает начало изменений из вашей ветки.
   - `=======` разделяет ваш код и код из другой ветки.
   - `>>>>>>>` обозначает конец изменений из другой ветки.

3. **Решить конфликт:**
   - Проанализируйте изменения из обеих веток и решите, какие изменения следует сохранить.
   - Удалите метки `<<<<<<<`, `=======` и `>>>>>>>`, а также ненужные части кода.
   - Оставьте только те изменения, которые необходимо сохранить после слияния.

4. **Добавить изменения и завершить слияние:**
   - После разрешения конфликта сохраните изменения в файле.
   - Добавьте изменения в индекс с помощью команды `git add <file_name>`.
   - Завершите слияние с помощью команды `git merge --continue`.


## 21. Что такое Git Cherry pick? (Git)

https://www.atlassian.com/ru/git/tutorials/cherry-pick#

`git cherry-pick` — это полезная команда, с помощью которой можно выборочно применить коммиты Git к текущей рабочей ветке HEAD. С ее помощью можно выбрать коммит из одной ветки и применить его к другой. Команда `git cherry-pick` — это удобный способ отменить изменения. Например, если коммит попал в ветку по ошибке, вы можете переключиться на нужную ветку и выполнить перенос.

Пользоваться командой `git cherry-pick` удобно, однако это не всегда оптимально. Она может привести к дублированию коммитов, поэтому нередко разработчики предпочитают обычное слияние. Таким образом, можно сказать, что команда `git cherry-pick` — средство эффективное, но узконаправленное.

Пример использования:
Если был обнаружен баг, важно как можно скорее предоставить исправление конечным пользователям. Рассмотрим пример, когда разработчик начинает создавать новую функцию. `В ходе работы обнаруживается существующий баг`, и разработчик создает специальный коммит для его исправления. Этот `коммит можно перенести прямо в основную ветку (main)`, чтобы исправить баг, прежде чем от него пострадают другие пользователи.

## 22. С какими системами/платформами для построения pipelines приходилось работать? (CI/CD)

Jenkins, GitHub Actions, GitLab

## 23. Приходилось ли работать с Ansible, Chef, Terraform? (IaC)

Использование инструментов автоматизации: Для реализации Infrastructure as Code используются инструменты автоматизации, такие как Ansible, Terraform, Chef, Puppet, CloudFormation, Azure Resource Manager и другие. Эти инструменты позволяют развертывать, настраивать и управлять инфраструктурой с использованием кода.

Преимущества подхода Infrastructure as Code включают повышение скорости развертывания инфраструктуры, повышение надежности и согласованности настроек, а также облегчение масштабирования и управления инфраструктурой.

IaC является ключевым элементом DevOps-практик, так как позволяет автоматизировать процессы управления инфраструктурой и интегрировать их в цикл непрерывной поставки (CI/CD).

## 24. Какие плюсы можешь назвать использования infrastructure as code? (IaC)

"Infrastructure as Code" (IaC) - это подход к управлению инфраструктурой IT-систем с использованием программного кода. Вместо ручного настройки серверов, сетей и других инфраструктурных ресурсов, инженеры описывают всю необходимую инфраструктуру в виде кода, который затем может быть автоматически развернут и управляем с использованием инструментов автоматизации.

Основные принципы Infrastructure as Code включают в себя:

1. Декларативное описание инфраструктуры: Инженеры описывают желаемое состояние инфраструктуры (например, какие серверы должны быть развернуты, какие настройки сети нужны и т.д.) в виде декларативного кода, вместо того, чтобы описывать шаги, необходимые для достижения этого состояния.

3. Версионирование и контроль изменений: Код, описывающий инфраструктуру, может быть хранен в системе контроля версий, что позволяет отслеживать изменения, вносимые в инфраструктуру, и возвращаться к предыдущим версиям в случае необходимости.

Преимущества подхода Infrastructure as Code включают повышение скорости развертывания инфраструктуры, повышение надежности и согласованности настроек, а также облегчение масштабирования и управления инфраструктурой.

## 25. Опиши что будет выполняться с task при её выполнении при помощи Ansible. (IaC)

Когда выполняется и при каких условиях?

1. 2 stage
2. Много jobs для каждого stage
3. Через maven в 1ой job запускается приложение.
4. Через maven в 2ой job запускаются тесты.
5. 3я и 4ая jobs выполняются из другого .gitlab-ci при условии push и MR

## 26. Ansible task. Что будет в результате выполнения этих задач? (IaC)

1. Есть 2 таски на скачивание приложения и его установку
2. Скачивание через ссылку. Сохранение в заданную директорию
3. Предоставление прав для директории 755.
4. Установка прилодения из заданной директории.

## 27. Что означает run once aggregate to localhost? (IaC)

- **ansible**: это утилита управления конфигурацией, которая позволяет автоматизировать развертывание, управление и настройку систем.
- **run once**: это опция Ansible, которая указывает, что задача должна быть выполнена только один раз, даже если группа хостов содержит несколько узлов.
- **aggregate**: в данном контексте может означать объединение или сгруппирование результатов выполнения задачи.
- **to localhost**: указывает, что задача должна быть выполнена на локальной машине, на которой запущен Ansible, а не на удаленных хостах.

Команда Ansible означает выполнение задачи только один раз на локальной машине (localhost) и возможно объединение результатов выполнения этой задачи.

## 28. Что такое handler в Ansible и зачем могут понадобиться? (IaC)

Handler в Ansible - это специальный тип задачи, который выполняется только в случае, если другая задача из playbook или роли изменила состояние системы. Handler может быть вызван с помощью модуля `notify` в других задачах, и он выполнится только один раз в конце выполнения playbook, если были изменения, требующие его выполнения.

Handler'ы могут понадобиться в следующих случаях:
1. **Перезапуск сервисов**: Если в процессе выполнения playbook были внесены изменения, требующие перезапуска сервисов, handler может быть использован для выполнения перезапуска только после всех изменений.
2. **Копирование файлов**: Если необходимо скопировать файлы или конфигурации на удаленные хосты после изменений, handler может обеспечить выполнение этого действия только по необходимости.
3. **Уведомления и оповещения**: Handler'ы могут использоваться для отправки уведомлений или оповещений после завершения определенных действий.

Использование handler'ов помогает оптимизировать выполнение playbook'ов, избегая лишних операций и упрощая управление конфигурацией системы.

## 29. Что такое роли в Ansible? (IaC)
sber/education/interview.md - 26. Что такое роли в Ansible?

В Ansible, роли (Roles) представляют собой организационную единицу, которая позволяет группировать связанные задачи, переменные, шаблоны и файлы в единый пакет для более удобного управления конфигурацией и автоматизации. Роли позволяют создавать переиспользуемые компоненты конфигурации, которые могут быть легко применены к различным хостам и инфраструктуре.

Основные компоненты роли в Ansible:

1. Задачи (Tasks): Задачи представляют собой действия, которые нужно выполнить на целевой системе. Например, установка пакетов, настройка сервисов, копирование файлов и т.д.

2. Переменные (Variables): Переменные используются для хранения значений, которые могут быть использованы в задачах и шаблонах. Они позволяют сделать роли более гибкими и настраиваемыми.

3. Шаблоны (Templates): Шаблоны представляют собой файлы с динамическим содержимым, которые могут быть применены к целевой системе. Например, конфигурационные файлы, скрипты и т.д.

4. Файлы (Files): Файлы, которые должны быть скопированы на целевую систему без изменений.

5. Обработчики (Handlers): Обработчики представляют собой действия, которые должны быть выполнены при определенных условиях. Например, перезапуск сервиса после изменения конфигурационного файла.

Роли позволяют создавать модульные и переиспользуемые компоненты конфигурации, которые могут быть легко включены в плейбуки (playbooks) Ansible для автоматизации развертывания и управления инфраструктурой.

## 30. С какими системами мониторинга приходилось работать? (Monitoring)(ОПЫТ)
sber/devices/interview.md - 5. Мониторинг. Какой стек использовал?

1. Использование стека grafana + prometheus + node exporter
2. Использование Instana + Instana agents

## 31. Есть бэк-приложение. HTTP сервер на Spring. Нужно поставить на мониторинг. Какие метрики смотрел бы в 1ую очередь? (Monitoring)

При мониторинге бэкэнд-приложения на Spring HTTP сервере, в первую очередь стоит обратить внимание на следующие ключевые метрики:

1. **Производительность HTTP сервера**:
   - Загрузка CPU и памяти на сервере
   - Количество запросов в секунду
   - Среднее время ответа на запросы

2. **Статусы HTTP запросов**:
   - Коды ответов HTTP (200, 404, 500 и т.д.)
   - Количество успешных и неуспешных запросов

3. **Использование базы данных** (если используется):
   - Загрузка CPU и памяти на сервере базы данных
   - Количество запросов к базе данных
   - Среднее время выполнения запросов к базе данных

4. **Сборщик мусора Java**:
   - Использование памяти Java
   - Частота и длительность сборок мусора

5. **Кэширование**:
   - Попадания и промахи кэша
   - Эффективность кэширования

Для сбора и визуализации этих метрик через Grafana и Prometheus, вам потребуется настроить экспортеры для сбора метрик с HTTP сервера, базы данных (если используется) и других компонентов. Например, для сбора метрик из базы данных можно использовать экспортеры, такие как `Prometheus MySQL Exporter` или `Prometheus PostgreSQL Exporter`.

Эти метрики помогут вам отслеживать производительность и работоспособность вашего бэкэнд-приложения, а также выявлять потенциальные проблемы и улучшать его работу.

## 32. Логирование. Какой стек использовал? (Monitoring)(ОПЫТ)
sber/devices/interview.md - 6. Логирование. Какой стек использовал? 

### Сборка и визуализация логов в Grafana с использованием Loki:

Для логирования на проекте, где уже используется стек мониторинга Grafana + Prometheus, хорошим выбором будет использование Loki в сочетании с Grafana для хранения и визуализации журналов.

Для быстрой настройки логирования докер контейнеров на сервере Linux с использованием Loki и Grafana, вам потребуется выполнить следующие шаги:

1. **Установка и настройка Loki**:
   - Установите Loki на сервере. Можно использовать Docker:
     ```bash
     docker run -d --name loki -p 3100:3100 grafana/loki:latest
     ```
   - Убедитесь, что Loki запущен и доступен по адресу `http://localhost:3100`.

2. **Настройка логирования в докер контейнерах**:
   - Добавьте следующий параметр в запуск контейнера для отправки логов в Loki:
     ```bash
     --log-driver=loki --log-opt loki-url="http://<loki_ip>:3100/loki/api/v1/push"
     ```
   - Перезапустите контейнеры, чтобы применились изменения.

3. **Настройка Grafana для визуализации логов**:
   - Установите Grafana на сервере, если еще не установлено.
   - Добавьте источник данных Loki в Grafana, указав адрес Loki (http://localhost:3100).
   - Создайте панели для визуализации журналов из Loki.

## 33. Каким образом передавались логи в хранилище? Кто отправляет/пишет их? (Loki/Kibana)

Для передачи логов в хранилище, как Loki, так и Kibana, обычно используются агенты логирования или лог-драйверы, которые отправляют или пишут логи в соответствующее хранилище. В случае Loki, контейнеры Docker могут напрямую отправлять логи в Loki, указывая адрес Loki в параметрах запуска контейнера. Для Kibana, обычно используется Elasticsearch как хранилище логов, и логи отправляются в Elasticsearch через лог-драйверы или агенты логирования.

Примеры команд и шагов для поднятия Loki и Kibana в Docker:

1. **Loki**:
   - Запуск контейнера Loki:
     ```bash
     docker run -d --name loki -p 3100:3100 grafana/loki:latest
     ```
   - Убедитесь, что Loki доступен по адресу `http://localhost:3100`.

2. **Kibana** (с Elasticsearch):
   - Запуск контейнера Elasticsearch:
     ```bash
     docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.15.1
     ```
   - Запуск контейнера Kibana:
     ```bash
     docker run -d --name kibana --link elasticsearch:elasticsearch -p 5601:5601 docker.elastic.co/kibana/kibana:7.15.1
     ```
   - Убедитесь, что Kibana доступен по адресу `http://localhost:5601`.

После выполнения этих шагов, Loki и Kibana будут запущены в Docker контейнерах, и вы сможете начать отправлять и визуализировать логи в соответствующих хранилищах. Помните, что для более продуктивного использования, необходимо настроить агенты логирования в ваших контейнерах для отправки логов в Loki или Elasticsearch.

## 34. С какими веб серверами приходилось работать? Какие есть еще кроме nginx?

- Apache HTTP Server
- Microsoft IIS (Internet Information Services)
- LiteSpeed Web Server
- Caddy
- OpenLiteSpeed
- Apache Tomcat (для Java приложений)
- и другие.

Каждый из этих веб-серверов имеет свои особенности и подходит для разных типов приложений и сценариев использования.

## 35. Nginx у нас на сервере как балансировщик нагрузки. Есть 4 бэк сервера, на которых развёрнуто одинаковое приложение. Какие есть способы балансировки запросов между бэк серверами?

Для балансировки запросов между бэкенд серверами с помощью Nginx в качестве балансировщика нагрузки, можно использовать различные методы балансировки, такие как round-robin, least connections, ip-hash и другие.

Пример команд и шагов для настройки балансировки запросов с использованием Nginx:

- Установите Nginx на сервере, если он еще не установлен.
- Отредактируйте конфигурационный файл Nginx (обычно располагается в `/etc/nginx/nginx.conf` или `/etc/nginx/sites-available/default`) и добавьте блок для балансировки нагрузки:

```nginx
http {
    upstream backend {
        server backend1:80;
        server backend2:80;
        server backend3:80;
        server backend4:80;
    }

    server {
        listen 80;

        location / {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}
```

- Перезапустите Nginx для применения изменений:

```bash
sudo systemctl restart nginx
```

После выполнения этих шагов, Nginx будет балансировать запросы между четырьмя бэкенд серверами, на которых развернуто одинаковое приложение. Вы можете настроить и другие параметры балансировки в соответствии с вашими потребностями.

## 36. Приходилось ли настраивать CORS (Cross-Origin Resource Sharing)? Что это?

CORS (Cross-Origin Resource Sharing) - это механизм, который позволяет веб-странице запрашивать ресурсы с другого источника (домена, протокола или порта), отличного от источника, с которого была загружена сама страница. Это важная мера безопасности, которая помогает предотвратить атаки с использованием скриптов на стороне клиента.

Пример настройки CORS в Nginx:

1. Откройте конфигурационный файл Nginx (обычно располагается в `/etc/nginx/nginx.conf` или `/etc/nginx/sites-available/default`).

2. Добавьте следующие строки для разрешения CORS для всех ресурсов:

```nginx
server {
    listen 80;
    server_name example.com;

    location / {
        add_header 'Access-Control-Allow-Origin' '*';
        add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
        add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range';
    }
}
```

3. Перезапустите Nginx для применения изменений:

```bash
sudo systemctl restart nginx
```

Теперь сервер Nginx будет отправлять заголовки CORS в ответ на запросы, разрешая доступ к ресурсам с других источников.

## 37. Какой-нибудь http заголовок сможешь назвать, который постоянно используется? Именно в протоколе - a header

Несколько примеров HTTP заголовков, которые часто используются:

Заголовок `('Content-Type', 'application/json')` используется для указания, что контент запроса или ответа является JSON-данными. Он помогает клиенту и серверу правильно интерпретировать передаваемые данные.

- `Content-Type`: указывает тип контента в теле запроса или ответа, например, `application/json`.
- `Authorization`: содержит информацию для аутентификации пользователя, обычно используется для передачи токена доступа.
- `User-Agent`: содержит информацию о браузере или приложении, отправляющем запрос.
- `Accept`: указывает, какие типы контента клиент может принять от сервера.

Пример создания заголовков в JS коде:

```javascript
const headers = new Headers();
headers.append('Content-Type', 'application/json');
headers.append('Authorization', 'Bearer token123');

fetch('https://api.example.com/data', {
    method: 'GET',
    headers: headers
})
.then(response => {
    // Обработка ответа
})
.catch(error => {
    // Обработка ошибки
});
```

В этом примере создаются и добавляются HTTP заголовки `Content-Type` и `Authorization` к запросу, отправляемому с помощью функции `fetch` в JavaScript.

## 38. С какими БД работал? Какие задачи были связанные с БД? (БД)

1) Реляционные (например, MySQL, PostgreSQL), NoSQL (например, MongoDB, Redis) и облачные базы данных (например, Amazon RDS, Google Cloud Firestore).

Примеры часто используемых баз данных и их отличия:

- MySQL vs PostgreSQL:
  - MySQL: широко распространенная реляционная база данных, хорошо подходит для простых приложений с небольшим объемом данных. Имеет хорошую производительность при чтении данных.
  - PostgreSQL: также реляционная база данных, но более мощная и расширяемая. Поддерживает более сложные запросы и транзакции, что делает ее хорошим выбором для более сложных приложений.

- MongoDB vs Redis:
  - MongoDB: NoSQL база данных, хранящая данные в формате JSON-подобных документов. Хорошо подходит для приложений с гибкой схемой данных и потребностью в масштабируемости.
  - Redis: NoSQL база данных, работающая в оперативной памяти. Используется для кэширования данных и обработки высоконагруженных операций, таких как счетчики и сессии.

2) Задачи, связанные с базами данных:

- Установка и настройка баз данных на серверах.
- Резервное копирование и восстановление данных.
- Масштабирование и оптимизация производительности баз данных.
- Мониторинг и управление ресурсами баз данных.
- Автоматизация процессов управления базами данных с помощью инструментов DevOps, таких как Ansible, Terraform, Docker.

## 39. Основы управления и мониторинга баз данных. Основы NoSQL баз данных и их отличия. Инструменты автоматизации. (БД)

1) **Основы NoSQL баз данных и их отличия от реляционных баз данных:**

NoSQL базы данных отличаются от реляционных тем, что они не используют традиционную таблицу с рядами и столбцами для хранения данных. Вместо этого они используют различные модели данных, такие как документы, ключ-значение, столбцы или графы. Основные отличия включают:

- **Гибкая схема данных:** NoSQL базы данных позволяют хранить данные без строгой схемы, что упрощает добавление новых полей или изменение структуры данных без необходимости изменения всей базы данных.

- **Горизонтальное масштабирование:** NoSQL базы данных легче масштабируются горизонтально, что означает добавление новых узлов для увеличения производительности и хранения больших объемов данных.

Пример отличия: 
В реляционной базе данных для хранения информации о пользователях и их заказах может потребоваться несколько таблиц (например, таблица пользователей и таблица заказов), связанных внешними ключами. В то время как в NoSQL базе данных, такой же набор данных может быть храниться в виде документов, где каждый документ содержит информацию о пользователе и его заказах вместе.

2) **Основы управления и мониторинга баз данных:**

Мониторинг баз данных включает в себя отслеживание производительности, доступности, использования ресурсов и обнаружение проблем. Пример мониторинга базы данных может включать:

- Отслеживание запросов и времени выполнения.
- Мониторинг использования памяти, CPU и дискового пространства.
- Оповещения о сбоях или недоступности базы данных.
- Анализ долгих или заблокированных запросов.

Для мониторинга базы данных могут использоваться инструменты, такие как Prometheus, Grafana, Nagios, Zabbix и многие другие.

3) **Инструменты автоматизации и оркестрации для работы с базами данных в инфраструктуре:**

Пример автоматизации работы с базами данных может включать использование инструментов, таких как Ansible, Terraform, Docker и Kubernetes. Например, с помощью Ansible можно автоматизировать установку и настройку баз данных на серверах, с Terraform можно создавать и управлять инфраструктурой, а с помощью Docker и Kubernetes можно упаковывать и развертывать базы данных в контейнерах.

Небольшой пример автоматизации с использованием Ansible:
```yaml
- name: Установка PostgreSQL
  hosts: database_servers
  tasks:
    - name: Установка PostgreSQL
      apt:
        name: postgresql
        state: present
```

В этом примере с помощью Ansible выполняется установка PostgreSQL на серверах, указанных в группе `database_servers`.

## 40. Как работает репликация в PostgreSQL и MySQL? Каких видов бывает и чем отличается? (БД)

**Репликация в PostgreSQL:**

Репликация в PostgreSQL - это процесс создания и поддержания точной копии базы данных (мастера) на одном или нескольких других серверах (реплики) для повышения отказоустойчивости, масштабируемости и увеличения доступности данных. Репликация в PostgreSQL может быть настроена с использованием различных методов:

1) **Логическая репликация:** В этом методе изменения данных на мастере записываются в специальные журналы, которые затем передаются и применяются на репликах. Этот метод позволяет более гибко настраивать репликацию и переносить только определенные данные.

2) **Физическая репликация:** В этом методе данные копируются байт в байт с мастера на реплики. Этот метод более эффективен с точки зрения производительности, так как данные передаются в бинарном формате.

3) **Смешанная репликация:** Комбинация логической и физической репликации, позволяющая достичь оптимального баланса между гибкостью и производительностью.

**Репликация в MySQL:**

В MySQL также существует несколько видов репликации:

1) **Мастер-мастер репликация:** В этом случае оба сервера могут одновременно принимать записи и реплицировать их друг на друга. Это позволяет балансировать нагрузку и обеспечивать отказоустойчивость.

2) **Мастер-репликация:** В этом случае один сервер (мастер) принимает записи, а другие сервера (реплики) получают их и воспроизводят. Этот метод обеспечивает масштабируемость и отказоустойчивость.

3) **Цепочка репликации:** В этом методе репликация осуществляется через цепочку серверов, где каждый следующий сервер является репликой предыдущего. Это позволяет создавать сложные схемы репликации для улучшения производительности и отказоустойчивости.

**Отличия:**

- PostgreSQL поддерживает как логическую, так и физическую репликацию, в то время как MySQL имеет более широкий выбор методов репликации, включая мастер-мастер и цепочку репликации.
- В PostgreSQL логическая репликация позволяет более гелко настраивать репликацию и переносить только определенные данные, в то время как в MySQL мастер-мастер репликация обеспечивает балансировку нагрузки между серверами.
- Оба СУБД обеспечивают высокую отказоустойчивость и масштабируемость с помощью репликации, но методы их реализации могут различаться.

## 41. В чем разница между виртуализацией и контейнеризацией (как подходов к деплою приложений). Где преимущества 1го и другого и их недостатки?

**Виртуализация:**

- **Определение:** Виртуализация - это технология, которая позволяет создавать виртуальные экземпляры аппаратного обеспечения (виртуальные машины), на которых можно запускать различные операционные системы и приложения.
- **Преимущества:**
   - Изоляция: Каждая виртуальная машина имеет свою собственную операционную систему и ресурсы, что обеспечивает высокую степень изоляции между приложениями.
   - Гибкость: Виртуальные машины могут быть легко масштабированы и перемещены между физическими серверами.
   - Поддержка различных ОС: Виртуализация позволяет запускать приложения, требующие различных операционных систем, на одном физическом сервере.

- **Недостатки:**
   - Использование ресурсов: Виртуальные машины требуют дополнительных ресурсов для работы гипервизора и операционной системы каждой виртуальной машины.
   - Запуск времени: Запуск и инициализация виртуальных машин может занимать больше времени, чем контейнеры.

**Контейнеризация:**

- **Определение:** Контейнеризация - это технология, которая позволяет упаковывать приложения и все их зависимости в изолированные контейнеры, которые могут быть запущены на любом совместимом хосте.
- **Преимущества:**
   - Легковесность: Контейнеры используют общий ядро операционной системы хоста, что делает их более легковесными и экономичными по сравнению с виртуальными машинами.
   - Быстрый запуск: Контейнеры запускаются гораздо быстрее, чем виртуальные машины, так как они не требуют полной инициализации операционной системы.
   - Изолированность: Контейнеры обеспечивают изоляцию приложений друг от друга, но используют общие ресурсы операционной системы хоста.

- **Недостатки:**
   - Ограничения ОС: Контейнеры обычно работают на одной операционной системе, поэтому приложения, требующие различных ОС, могут столкнуться с ограничениями.
   - Управление ресурсами: Контейнеры могут иметь ограниченный доступ к ресурсам хоста, что может потребовать более тщательного управления ресурсами.

**Вывод:**

- Виртуализация обеспечивает высокую изоляцию и поддержку различных операционных систем, но требует больше ресурсов.
- Контейнеризация более легковесна, быстрее и обеспечивает гибкость в развертывании, но может иметь ограничения по операционным системам.
- Выбор между виртуализацией и контейнеризацией зависит от конкретных требований проекта, таких как уровень изоляции, использование ресурсов и скорость развертывания.

## 42. Cgroups изолируют ресурсы для контейнеров. Какая еще технология используется для контейнеризации? Ресурсы мы изолировали, но какая технология отвечает за процессы, которые мы видим в контейнерах? (Linux)
sber/devices/interview.md - 11. Какие namespaces бывают? (Linux)

Для контейнеризации на Linux помимо **cgroups** (Control Groups), которые изолируют и управляют ресурсами, также используется технология **Namespaces**.

**Namespaces** - это механизм Linux, который обеспечивает изоляцию различных системных ресурсов для процессов. Когда процесс запускается в контейнере, он видит только свой собственный "виртуальный" вид операционной системы, созданный с помощью Namespaces. Это включает в себя изоляцию процессов, сетевых интерфейсов, файловых систем, IPC (межпроцессное взаимодействие) и других ресурсов.

Таким образом, **Namespaces** отвечают за изоляцию и виртуализацию системных ресурсов, делая контейнеры независимыми и безопасными для выполнения различных процессов внутри них.

- **Docker** является платформой для разработки, развертывания и управления контейнеризированными приложениями. Docker предоставляет удобный интерфейс и инструменты для создания, управления и запуска контейнеров на основе технологий, таких как Control Groups и Namespaces.

- **Runtime** в контексте контейнеризации обычно относится к программному обеспечению, которое отвечает за запуск и управление контейнерами. Одним из популярных рантаймов является **containerd**, который управляет жизненным циклом контейнеров, включая их создание, запуск, остановку и удаление.

- **Технологии в ядре (Kernel technologies)** относятся к различным механизмам и функциям, предоставляемым ядром операционной системы. В контексте контейнеризации на Linux, технологии в ядре, такие как Control Groups и Namespaces, обеспечивают изоляцию и управление ресурсами для контейнеров.

- **Docker** использует комбинацию **Control Groups** и **Namespaces** для обеспечения изоляции контейнеров. Control Groups позволяют управлять ресурсами, такими как CPU, память и дисковое пространство, в то время как Namespaces обеспечивают изоляцию процессов, сети и других системных ресурсов. Docker использует эти технологии в ядре Linux для создания и управления контейнерами, обеспечивая их изолированность и безопасность.

## 43. В Dockerfile может быть несколько директив "FROM"?

Нет, в Dockerfile может быть только одна директива "FROM". Директива "FROM" в Dockerfile определяет базовый образ, который будет использоваться для создания текущего образа. Каждый Dockerfile должен начинаться с директивы "FROM", которая указывает на базовый образ, от которого будет производиться сборка.

Если вам необходимо использовать несколько базовых образов или комбинировать функциональность из нескольких образов, вы можете создать многоэтапный сборочный процесс, где каждый этап использует свой собственный "FROM". В этом случае каждый этап будет создавать временный образ, который будет использоваться в следующем этапе сборки.

Например, многоэтапный Dockerfile может выглядеть следующим образом:

```
# Этап 1: Сборка приложения
FROM node:alpine AS build
WORKDIR /app
COPY . .
RUN npm install
RUN npm run build

# Этап 2: Запуск приложения
FROM nginx:alpine
COPY --from=build /app/dist /usr/share/nginx/html
```

Здесь первый этап использует образ Node.js для сборки приложения, а второй этап использует образ Nginx для запуска приложения.

## 44. Удавалось ли самостоятельно разворачивать k8s на bare metal? Если да - то через что? (k8s)

Возможно развернуть Kubernetes (k8s) на bare metal (физических серверах) без использования облачных провайдеров. Для этого можно использовать различные инструменты и подходы. Один из популярных инструментов для развертывания Kubernetes на bare metal - это **kubeadm**.

Шаги для развертывания Kubernetes на bare metal с использованием **kubeadm**:

1. **Подготовка серверов**:
   - Установите операционную систему на каждом сервере (например, Ubuntu, CentOS).
   - Убедитесь, что серверы могут связываться друг с другом по сети.

2. **Установка Docker и kubeadm**:
   - Установите Docker на каждом сервере.
   - Установите kubeadm, kubelet и kubectl на каждом сервере.

3. **Инициализация кластера**:
   - На одном из серверов выполните команду `kubeadm init` для инициализации кластера Kubernetes.
   - Следуйте инструкциям, чтобы добавить необходимые параметры.

4. **Присоединение рабочих узлов**:
   - На остальных серверах выполните команду `kubeadm join`, указав токен, который был сгенерирован при инициализации.

5. **Установка сетевого плагина**:
   - Установите сетевой плагин (например, Calico, Flannel) для обеспечения сетевой связности между подами.

Это базовый пример процесса развертывания Kubernetes на bare metal с использованием kubeadm. Для более сложных сценариев и настройки существуют другие инструменты, такие как kubespray, Rancher, и т. д. Каждый из них имеет свои особенности и требования.

https://github.com/JavaScriptonit/kubespray-ansible - Steps to deploy kubespray-ansible

## 45. Из каких служб состоит k8s? (k8s)

Kubernetes (k8s) состоит из следующих основных компонентов:

1. **kube-apiserver**: Компонент, который предоставляет API для управления кластером Kubernetes. Все операции в Kubernetes проходят через kube-apiserver.

2. **kube-controller-manager**: Компонент, который запускает различные контроллеры, отвечающие за управление состоянием кластера, контролируя ресурсы и обеспечивая желаемое состояние.

3. **kube-scheduler**: Компонент, который отвечает за планирование запуска подов на рабочих узлах в кластере.

4. **kubelet**: Агент, который работает на каждом рабочем узле и отвечает за управление контейнерами и подами на этом узле.

5. **kube-proxy**: Компонент, который обеспечивает сетевую проксировку в кластере и управляет сетевым доступом к сервисам.

6. **etcd**: Распределенное хранилище ключ-значение, которое используется Kubernetes для хранения всех данных конфигурации кластера.

Эти основные компоненты обеспечивают функциональность и управление кластером Kubernetes. Кроме того, существуют и другие дополнительные компоненты, такие как DNS-сервер, мониторинг и логирование, которые могут быть интегрированы в кластер для дополнительной функциональности и возможностей.

## 46. Может ли быть в pod больше 1го контейнера? И когда? (k8s)

Да, в Kubernetes в одном Pod может быть запущено более одного контейнера. Это называется **Multi-Container Pods**. Обычно в Pod находится один основной контейнер, который выполняет основную функцию приложения, и дополнительные вспомогательные контейнеры, которые могут выполнять различные задачи в поддержку основного контейнера.

Вот несколько причин, почему в Pod могут быть размещены несколько контейнеров:

1. **Совместное использование ресурсов**: Дополнительные контейнеры могут использовать общие ресурсы с основным контейнером, такие как файлы, сеть или тома данных.

2. **Совместная работа**: Контейнеры в одном Pod могут взаимодействовать друг с другом напрямую через локальный интерфейс, облегчая совместную работу и обмен данными.

3. **Шаблонные паттерны**: Например, контейнеры-сайдкары могут использоваться для добавления дополнительной функциональности, такой как логирование, мониторинг или обновление конфигурации, к основному контейнеру без изменения его кода.

4. **Разделение ответственности**: Разные контейнеры могут быть ответственны за различные аспекты работы приложения, что может способствовать улучшению модульности и облегчению управления.

Хотя Multi-Container Pods могут быть полезны в некоторых случаях, их следует использовать осторожно, чтобы не усложнять развертывание и управление. Каждый контейнер в Pod должен выполнять четко определенную задачу и быть легко масштабируемым и управляемым.

## 47. В каких ситуациях может DS пригодиться? Что такое DaemonSet? (k8s)

DaemonSet (DS) в Kubernetes - это ресурс, который гарантирует, что на каждом узле кластера будет запущен экземпляр пода. DS может быть полезен во многих ситуациях, включая:

1. **Сетевые сервисы**: DS может использоваться для развертывания сетевых сервисов, таких как сетевые прокси, мониторинговые агенты или сетевые решения безопасности, на каждом узле кластера.

2. **Логирование и мониторинг**: DS может быть использован для развертывания агентов логирования или мониторинга на каждом узле, чтобы обеспечить сбор и анализ данных с узлов кластера.

3. **Хранение данных**: DS может быть использован для развертывания узлов хранения данных на каждом узле, чтобы обеспечить доступ к данным на уровне узла.

4. **Системные агенты**: DS может быть использован для развертывания системных агентов, таких как агенты обновления, антивирусные программы или агенты управления узлами, на каждом узле кластера.

5. **Распределенные приложения**: DS может быть использован для развертывания частей распределенного приложения на каждом узле кластера, чтобы обеспечить доступность и отказоустойчивость.

DS обеспечивает удобный способ развертывания и управления приложениями, которые должны работать на каждом узле кластера. Он гарантирует, что приложение будет запущено на каждом узле и обеспечивает автоматическое масштабирование и обновление.

## 48. Создан pod. Статус - "Image pull back off" (образ не смог стянуть). Это приватный реестр. Куда смотреть? Как исправить? (k8s)

Когда Pod не может загрузить образ из приватного реестра, это может быть вызвано различными причинами. Вот несколько шагов, которые можно предпринять, чтобы исправить проблему:

1. **Проверьте доступ к реестру**: Убедитесь, что кластер Kubernetes имеет доступ к приватному реестру образов. Это может потребовать настройки правильных учетных данных (логин/пароль или токен) или использование секретов Kubernetes для доступа к реестру.

2. **Проверьте правильность имени образа**: Убедитесь, что имя образа в манифесте Pod правильно указано и соответствует образу в приватном реестре.

3. **Проверьте наличие секретов**: Если для доступа к приватному реестру требуются учетные данные, убедитесь, что в кластере созданы и правильно настроены секреты Kubernetes.

4. **Проверьте настройки безопасности**: Проверьте, нет ли ограничений на доступ к приватному реестру из кластера Kubernetes, таких как сетевые политики или правила файрвола.

5. **Проверьте логи контейнера**: Просмотрите логи контейнера, чтобы увидеть более подробную информацию о проблеме с загрузкой образа. Это может помочь выявить конкретную ошибку.

6. **Попробуйте повторно запустить Pod**: Иногда проблема с загрузкой образа может быть временной. Попробуйте повторно запустить Pod и посмотрите, устранится ли проблема.

7. **Используйте Docker-конфиг**: Если используется Docker-конфиг для доступа к приватному реестру, убедитесь, что он правильно сконфигурирован и доступен в кластере Kubernetes.

### Из личного опыта: 

1. Проблема с сертификатом. Нужно проверить его наличие, создать новый
2. Проблема с прокси. Посмотреть настройки прокси на сервере, в контейнере. Проверить сетевой доступ до реестра через прокси или убрать прокси из конфигов.

## 49. Создали ingress, который смотрит на сервис, а сервис смотрит на поды. Делая запрос на ingress - получаем ошибку. Запрос до pod не доходит (запроса нет в логах пода). Как исправить? Куда смотреть? (k8s)

Когда запросы не доходят до Pod через Ingress в Kubernetes, это может быть вызвано различными причинами. Вот несколько шагов, которые можно предпринять для анализа и исправления проблемы:

1. **Проверьте конфигурацию Ingress**:
   - Убедитесь, что правильно настроены правила маршрутизации в Ingress для отправки запросов на нужный сервис.
   - Проверьте, что хост и путь в Ingress соответствуют вашему запросу.

2. **Проверьте конфигурацию сервиса**:
   - Убедитесь, что сервис правильно настроен для перенаправления трафика на поды.
   - Проверьте, что селекторы сервиса соответствуют меткам Pod.

3. **Проверьте конфигурацию Pod**:
   - Убедитесь, что Pod правильно настроен и работает корректно.
   - Проверьте логи Pod, чтобы убедиться, что запросы доходят до Pod и обрабатываются правильно.

4. **Проверьте сетевую конфигурацию**:
   - Убедитесь, что сетевые политики Kubernetes не блокируют трафик между Ingress, сервисами и Pod.
   - Проверьте доступность сетевых портов и правила файрвола.

5. **Используйте утилиты для диагностики**:
   - Используйте `kubectl describe` для проверки статуса Ingress, сервисов и Pod.
   - Используйте `kubectl logs` для просмотра логов Ingress, сервисов и Pod.

6. **Проверьте статусы ресурсов**:
   - Проверьте статус Ingress, сервисов и Pod с помощью `kubectl get`.
   - Убедитесь, что все ресурсы находятся в состоянии "Running" или "Active".

7. **Попробуйте перезапустить ресурсы**:
   - Попробуйте перезапустить Ingress, сервисы и Pod, чтобы устранить возможные проблемы с текущими экземплярами.

## 50. Что такое HELM? (HELM)

**HELM** - это пакетный менеджер для Kubernetes, который упрощает установку, обновление и управление приложениями в Kubernetes с помощью предварительно созданных пакетов, называемых **чартами (charts)**. 

Вот некоторые ключевые особенности и преимущества использования HELM:

1. **Управление зависимостями**: HELM позволяет управлять зависимостями между различными компонентами приложения, что упрощает установку и обновление сложных приложений.

2. **Шаблоны конфигурации**: HELM использует шаблоны конфигурации, позволяя параметризовать конфигурацию приложения и создавать несколько экземпляров с разными настройками.

3. **Версионирование**: HELM поддерживает версионирование чартов и позволяет легко обновлять приложения до новых версий.

4. **Расширяемость**: HELM позволяет создавать собственные чарты и распространять их через репозитории, что упрощает совместное использование и повторное использование конфигурации.

5. **Удобный интерфейс командной строки**: HELM предоставляет удобный интерфейс командной строки для управления чартами, установки приложений и управления релизами.

Благодаря своей гибкости, удобству использования и возможности повторного использования конфигурации, HELM является популярным инструментом для управления приложениями в Kubernetes.

## 51. Приходилось ли писать чарты с 0 самостоятельно? (HELM)

**Написание чартов с нуля** может быть вызывающим заданием, особенно для новичков в использовании HELM. Вот некоторые сложности и особенности, с которыми можно столкнуться при написании чартов с нуля:

- **Структура чарта**: необходимо понимание структуры чарта, включая файлы `Chart.yaml`, `values.yaml`, `templates/`, `helpers/` и другие.
- **Шаблоны**: создание шаблонов конфигурации для различных ресурсов Kubernetes может потребовать понимания синтаксиса шаблонизации и функций HELM.
- **Зависимости**: управление зависимостями и подключение внешних чартов может быть сложным, особенно при работе с комплексными приложениями.
- **Тестирование**: важно тестировать чарты, чтобы убедиться, что они работают корректно и создают необходимые ресурсы в Kubernetes.

## 52. Приходилось ли использовать хуки и для чего они нужны? (HELM)

**Хуки (Hooks)** в HELM - это механизм, который позволяет выполнять определенные действия на различных этапах жизненного цикла релиза. Хуки могут быть использованы для выполнения дополнительных операций перед или после установки, обновления или удаления релиза. Например:

- **Pre-install и Post-install хуки**: позволяют выполнить действия до или после установки чарта.
- **Pre-upgrade и Post-upgrade хуки**: позволяют выполнить действия перед или после обновления чарта.
- **Pre-delete и Post-delete хуки**: позволяют выполнить действия перед или после удаления чарта.

Хуки могут быть использованы для различных целей, таких как запуск миграций данных, настройка окружения, уведомление других сервисов и т.д.

## 53. Пример использования Hooks в HELM. (HELM)

Пример использования **Pre-install хука** в чарте HELM. У нас есть чарт `myapp`, и мы хотим выполнить определенные действия перед установкой этого чарта.

1. Создадим файл `pre-install-job.yaml`, который будет содержать определение Job для выполнения хука:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: pre-install-job
spec:
  template:
    spec:
      containers:
      - name: pre-install-container
        image: busybox
        command: ['sh', '-c', 'echo "Pre-install hook executed"']
      restartPolicy: Never
  backoffLimit: 4
```

2. Добавим этот файл в директорию `templates/` нашего чарта.

3. В файле `templates/deployment.yaml` (или другом манифесте, который мы хотим изменить перед установкой), добавим аннотацию, чтобы указать HELM использовать наш Pre-install хук:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "5"
```

4. Теперь установим чарт `myapp` с использованием хука:

```bash
helm install myapp ./myapp
```

При установке чарта `myapp`, HELM выполнит Pre-install хук, который создаст Job с контейнером BusyBox, который просто выводит сообщение "Pre-install hook executed". Этот хук будет выполнен перед установкой ресурсов из чарта.

## 54. С какими системами управления VM приходилось работать? (VM)

Существует множество систем управления виртуальными машинами (VM), которые предоставляют различные функциональные возможности и подходы к управлению виртуализированными окружениями. Некоторые из наиболее популярных систем управления VM включают:

1. **VMware vSphere**: Это одна из самых распространенных платформ для виртуализации, предоставляющая широкий спектр функций для управления виртуальными машинами, виртуальными сетями и хранилищами.

2. **Microsoft Hyper-V**: Это гипервизор от Microsoft, который позволяет создавать и управлять виртуальными машинами на серверах под управлением Windows.

3. **KVM (Kernel-based Virtual Machine)**: Это гипервизор с открытым исходным кодом для Linux, который позволяет запускать виртуальные машины на хост-системе Linux.

4. **Xen**: Еще один гипервизор с открытым исходным кодом, который предоставляет виртуализацию на уровне хардвара для различных операционных систем.

5. **Oracle VM VirtualBox**: Это бесплатный гипервизор, который позволяет запускать виртуальные машины на рабочих станциях.

6. **Proxmox Virtual Environment**: Это платформа с открытым исходным кодом, объединяющая в себе виртуализацию на основе KVM и контейнеризацию на основе LXC.

Чаще всего используемыми системами управления виртуальными машинами являются VMware vSphere и Microsoft Hyper-V, благодаря своей популярности, широкому функционалу и поддержке от ведущих поставщиков облачных и виртуализационных решений. Однако выбор системы управления VM зависит от конкретных потребностей и требований организации.

## 55. Какие утилиты для сборки приложений использовал? (Сборка приложений)

Для сборки приложений существует множество утилит и инструментов, каждый из которых предназначен для определенных языков программирования и сред разработки. Некоторые из наиболее популярных утилит для сборки приложений в различных языках программирования:

1. **Maven**: Утилита для сборки Java-проектов, управления зависимостями, тестирования и документирования проектов. Maven использует файлы POM (Project Object Model) для описания проекта и его зависимостей.

2. **Gradle**: Еще один инструмент для сборки Java-проектов, который предлагает более гибкий и мощный подход к управлению зависимостями и конфигурацией проекта, чем Maven.

3. **PIP**: Утилита для управления пакетами Python. PIP используется для установки, обновления и удаления пакетов Python, а также для создания виртуальных окружений.

4. **npm (Node Package Manager)**: Утилита для управления зависимостями в проектах на JavaScript и Node.js. npm позволяет устанавливать и обновлять пакеты, а также выполнять скрипты сборки и тестирования.

5. **Make**: Классическая утилита для автоматизации сборки проектов на различных языках программирования. Make использует файлы Makefile для определения правил сборки и зависимостей.

6. **CMake**: Утилита для автоматизации сборки проектов на C и C++. CMake позволяет писать платформо-независимые скрипты сборки и генерировать файлы проектов для различных сред разработки.

Чаще всего используемыми утилитами для сборки приложений являются Maven, Gradle и npm, так как Java и JavaScript являются одними из самых популярных языков программирования. Однако выбор утилиты для сборки зависит от конкретных требований проекта, используемых технологий и предпочтений разработчиков.

## 56. Приходилось ли администрировать и дебажить Java приложения? 

Да, администрирование и дебаггинг Java приложений - важная часть работы разработчика или системного администратора. Вот основные шаги и рекомендации по администрированию и дебаггингу Java приложений:

**Администрирование Java приложений:**
1. **Мониторинг приложения**: Используйте инструменты мониторинга, такие как JConsole, JVisualVM или Prometheus, чтобы отслеживать производительность и состояние Java приложения.

2. **Настройка JVM параметров**: Изучите и оптимизируйте параметры JVM (Java Virtual Machine) для улучшения производительности приложения. Например, можно настроить размер кучи (heap size), сборку мусора (garbage collection) и другие параметры.

3. **Логирование**: Используйте библиотеки логирования, такие как Log4j или SLF4J, для записи информации о работе приложения. Правильное логирование поможет отслеживать ошибки и проблемы в приложении.

**Дебаггинг Java приложений:**
1. **Использование отладчика**: Используйте отладочные инструменты, такие как Eclipse IDE, IntelliJ IDEA или командную строку `jdb`, для пошагового выполнения кода, отслеживания значений переменных и обнаружения ошибок.

2. **Логирование**: Активно используйте логирование для отслеживания действий и состояния приложения во время выполнения. Логи могут помочь идентифицировать места возможных ошибок.

3. **Использование исключений**: Обрабатывайте исключения в приложении и используйте конструкцию `try-catch` для обнаружения и обработки ошибок.

**Основные команды:**
- `java` - запуск Java приложения
- `javac` - компиляция Java исходных кодов
- `jps` - вывод списка процессов Java
- `jstack` - вывод стека вызовов Java процесса
- `jmap` - создание карты памяти Java процесса
- `jstat` - вывод статистики использования памяти и производительности Java процесса

Следует помнить, что администрирование и дебаггинг Java приложений требует понимания основ Java-разработки, работы JVM и инструментов для мониторинга и дебаггинга.

## 57. Что такое GitOps? (Git)

**GitOps** - это методология управления инфраструктурой и процессом развертывания приложений, основанная на использовании систем контроля версий, таких как Git. Основная идея GitOps заключается в том, что вся инфраструктура и конфигурация приложений хранятся в репозитории Git, а изменения в этой конфигурации приводят к автоматическому обновлению инфраструктуры и приложений.

**Основные принципы GitOps:**
1. **Декларативное управление**: Инфраструктура и конфигурация приложений описываются в виде декларативных файлов (например, YAML), которые хранятся в Git репозитории.

2. **Автоматизация**: Изменения в Git репозитории автоматически приводят к обновлению инфраструктуры и приложений с использованием CI/CD пайплайнов.

3. **Синхронизация состояния**: Состояние инфраструктуры всегда должно соответствовать состоянию, описанному в Git репозитории. Если произошли изменения, система должна автоматически привести инфраструктуру к желаемому состоянию.

4. **Операционная безопасность**: Git история служит источником правды о том, какая конфигурация была задана и какие изменения были внесены, что обеспечивает операционную безопасность.

GitOps позволяет упростить управление инфраструктурой, обеспечить ее надежность и повысить скорость развертывания приложений. Этот подход особенно популярен в области облачных вычислений и контейнеризации, так как позволяет эффективно управлять инфраструктурой в современных динамичных средах разработки.

## 58. Что такое GitFlow? Как принято работать над задачей в ветке? (Git)

**GitFlow** - это модель ветвления и организации рабочего процесса при использовании системы контроля версий Git. Эта модель была предложена Vincent Driessen и стала популярной среди разработчиков благодаря своей структуре и четким правилам ветвления.

Основные принципы GitFlow включают в себя следующие типы веток:

1. **Master (основная ветка)**: В этой ветке содержится стабильная версия продукта. Новые изменения попадают в нее только после успешного завершения всех тестов.

2. **Develop (ветка разработки)**: В этой ветке ведется основная работа над новыми функциями и исправлением ошибок. От нее отводятся отдельные ветки для каждой задачи.

3. **Feature (ветка функции)**: Для каждой новой функции создается отдельная ветка от ветки `develop`. После завершения работы над функцией ветка сливается обратно в `develop`.

4. **Release (ветка релиза)**: Подготовка к выпуску новой версии происходит в этой ветке. В нее могут попадать исправления ошибок и подготовка документации.

5. **Hotfix (ветка исправлений)**: Используется для быстрого исправления критических ошибок в продакшене. Создается от `master` и после исправления сливается как в `master`, так и в `develop`.

Чтобы работать над задачей в ветке в соответствии с GitFlow, следуйте этим шагам:

1. Создайте ветку от ветки `develop` с названием, отражающим характер задачи:  
   ```bash
   git checkout develop
   git pull origin develop
   git checkout -b feature/new-feature
   ```

2. Работайте над задачей в созданной ветке, делая коммиты по мере продвижения работы.

3. После завершения задачи и тестирования, выполните слияние ветки с веткой `develop`:  
   ```bash
   git checkout develop
   git pull origin develop
   git merge --no-ff feature/new-feature
   git push origin develop
   ```

4. Удалите ветку, если она больше не нужна:  
   ```bash
   git branch -d feature/new-feature
   ```

Следование модели GitFlow помогает организовать рабочий процесс, упростить управление версиями и обеспечить стабильность разработки.

## 59. Что такое DevSecOps? Какие таски они добавляют в пайплайны? Какие задачи ставятся инженеру? (Git)

**DevSecOps** - это практика интеграции безопасности в процесс разработки и поставки программного обеспечения (DevOps). DevSecOps объединяет разработчиков, операционных специалистов и специалистов по информационной безопасности для обеспечения безопасности приложений с самого начала их жизненного цикла.

В пайплайны DevSecOps добавляются специфические таски, направленные на обеспечение безопасности приложений:

1. **Статический анализ кода (Static Code Analysis)**: Проверка и анализ исходного кода на предмет потенциальных уязвимостей и ошибок без его запуска.

2. **Динамический анализ безопасности (Dynamic Security Analysis)**: Запуск приложения для выявления уязвимостей и угроз в реальном времени.

3. **Анализ зависимостей (Dependency Analysis)**: Проверка наличия уязвимостей в сторонних библиотеках и зависимостях.

4. **Тестирование на проникновение (Penetration Testing)**: Специальные тесты, направленные на поиск уязвимостей с использованием методов хакеров.

5. **Мониторинг безопасности (Security Monitoring)**: Организация мониторинга безопасности приложения в реальном времени.

Инженеры, работающие в DevSecOps, сталкиваются с такими задачами:

1. **Интеграция безопасности в CI/CD пайплайны**: Настройка инструментов безопасности и автоматизация их использования в процессе разработки и поставки.

2. **Обучение и обучение персонала**: Обучение команды разработчиков и операционных специалистов в области безопасности и лучших практик DevSecOps.

3. **Разработка и внедрение политик безопасности**: Создание и внедрение стандартов безопасности для приложений и инфраструктуры.

4. **Реагирование на инциденты безопасности**: Быстрое реагирование на обнаруженные уязвимости и инциденты безопасности.

DevSecOps помогает снизить риски безопасности, повысить защиту приложений и обеспечить безопасность в целом в рамках DevOps процесса разработки и поставки программного обеспечения.