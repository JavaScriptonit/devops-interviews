# Список вопросов:

## Собеседование со Сбер Devices:
https://hh.ru/vacancy/83405120?hhtmFrom=employer_vacancies


# Terraform.

## 1. Что будет если 2 разработчика обновят файл .tfstate одновременно? (Terraform)

https://ru.hexlet.io/courses/terraform-basics/lessons/remote-state/theory_unit

`Terraform` хранит текущее состояние инфраструктуры в файле с расширением `.tfstate`. При выполнении операций `Terraform` идет в файл состояния и проверяет, какая инфраструктура уже развернута. На основе того, что есть в состоянии и что описано в проекте, `Terraform` понимает, что нужно сделать — создать инфраструктуру или изменить.

Если организовать этот процесс через `git-репозиторий`, нужно сначала обновить инфраструктуру, затем добавить коммит с новым `tfstate` и отправить его в удаленный репозиторий. Коллега должен получить из репозитория актуальный `tfstate`, внести свои изменения, и в свою очередь отправить изменения в коде `Terraform` и новый файл состояния в `Git`

### `Terraform remote backends`:

В терминологии Terraform backend — это решение, которое отвечает за хранение состояния. Если состояние хранится удаленно — это `remote backend`.

При использовании remote backend Terraform сохраняет состояние в удаленное хранилище, а локально в tfstate хранит только информацию об этом удаленном хранилище.

В качестве хранилища может выступать любое облачное объектное хранилище по типу `Amazon S3: Google Cloud Storage`, `Azure Storage`, `Yandex Cloud Storage` и другие подобные решения. Также Terraform может использовать для удаленного хранения состояния HTTP-сервер, базу данных PostgreSQL или облачную платформу Terraform Cloud.

В схеме с remote backend при выполнении любых операций над инфраструктурой Terraform будет обращаться к удаленному файлу состояния, блокировать его на время выполнения изменений, затем перезаписывать этот файл с учетом внесенных изменений

#### Как настроить хранение состояния в S3:
Подготавливаем облако для хранения состояния (Создадим в облаке S3-хранилище yc-hexlet-state объемом 10МБ. Этого хватит для хранения состояния надолго):
```
yc storage bucket create --name yc-hexlet-state --max-size 10000000
```
сделать табличку в облачной базе данных, где Terraform будет фиксировать блокировки состояния:
```
yc ydb database create terraform-state-lock --serverless

done (7s)
id: etnpkn3gs4s56qk9g7kf
folder_id: ...
created_at: ...
name: terraform-state-lock
...
document_api_endpoint: https://docapi.serverless.yandexcloud.net/ru-central1/b1gjrod3dvqni46u3paj/etnpkn3gs4s56qk9g7kf
```
Сохраним document_api_endpoint, он нам понадобится при конфигурации Terraform («Создать таблицу» и создадим документную таблицу lock с колонкой LockID типа String, которая будет являться ключом партиционирования)

через YandexCLI создадим сервисный аккаунт hexlet-remote, который будет сохранять состояние Terraform в облачное хранилище
```
yc iam service-account create --name hexlet-remote --description "SA to manage terraform state"

id: ajejk11p9ls1vvhc12mb
folder_id: ...
created_at: ...
name: hexlet-remote
description: SA to manage terraform state
```

Создадим в проекте файл backend.tf и вставим туда блок backend, описывающий хранение состояния:
```
terraform {
  backend "s3" {
    endpoint                    = "storage.yandexcloud.net"
    region                      = "ru-central1"
    bucket                      = "yc-hexlet-state"
    key                         = "hexlet-remote-state"
    access_key                  = "YCABX6vQXtCjoKu_oB7QabuZO"
    secret_key                  = "YCOL4xZ1tdpduS46z_YTlvDzYUwv8xBK_UuRq18m"
    dynamodb_endpoint           = "https://docapi.serverless.yandexcloud.net/ru-central1/b1gjrod3dvqni46u3paj/etnpkn3gs4s56qk9g7kf"
    dynamodb_table              = "lock"
    skip_region_validation      = true
    skip_credentials_validation = true
  }
}
```
Перенести локальный файл с состоянием в удаленное хранилище:
```
terraform init -migrate-state
```

Так мы с помощью удаленного хранения состояния в S3-хранилище и блокировки состояния в YDB добились того, что:

Состояние инфраструктуры всегда будет одинаковым и актуальным у всей команды. Локально в .tfstate проекта будет храниться только адрес удаленного бэкенда
Не возникнут конфликты одновременного обновления инфраструктуры двумя или более членами команды
Мы настроили удаленное хранение состояния. Осталось позаботиться о безопасности и о том, чтобы ключи для нашего хранилища не утекли в сеть.

## 2. Отличие Git stash от Git rebase? (Git)

### Git stash:

https://www.atlassian.com/ru/git/tutorials/saving-changes/git-stash

Команда `git stash` позволяет на время «сдать в архив» (или отложить) изменения, сделанные в рабочей копии, чтобы вы могли применить их позже. Откладывание изменений полезно, если вам необходимо переключить контекст и вы пока не готовы к созданию коммита.

Теперь вы можете вносить изменения, создавать новые коммиты, переключаться между ветками и выполнять другие операции Git. По необходимости отложенные изменения можно будет применить позже.

Отложенные изменения сохраняются в локальном репозитории Git и не передаются на сервер при выполнении команды push.

```
$ git status
Changes to be committed:
    new file:   style.css

$ git stash
Saved working directory and index state WIP on main: 5002d47 our new homepage
HEAD is now at 5002d47 our new homepage

$ git status
On branch main
nothing to commit, working tree clean
```

Применение отложенных изменений:
```
git stash pop
```

Управление несколькими наборами отложенных изменений:
```
$ git stash list
stash@{0}: WIP on main: 5002d47 our new homepage
stash@{1}: WIP on main: 5002d47 our new homepage
stash@{2}: WIP on main: 5002d47 our new homepage
```

`git stash show` - Просмотр различий между наборами отложенных изменений

`git stash branch` - Создание ветки из отложенных изменений

`git stash drop stash@{1}` - Удаление отложенных изменений

### Git rebase:

https://www.atlassian.com/ru/git/tutorials/rewriting-history/git-rebase

Перебазирование — это процесс перемещения последовательности коммитов к новому базовому коммиту или их объединение. Операцию перебазирования удобнее всего применить и отобразить в контексте создания функциональных веток. В общих чертах процесс можно представить следующим образом:

С точки зрения содержимого перебазирование — это замена одного коммита в основании ветки на другой, в результате чего создается впечатление, что ветка получила новое начало. В процессе этой операции Git создает новые коммиты и применяет их к указанному основанию, поэтому важно понимать, что в действительности ветка всегда состоит из совершенно новых коммитов.

`Интерактивное перебазирование позволяет полностью контролировать состояние истории проекта.` Это дает разработчикам большую свободу, поскольку они могут зафиксировать засоренную историю, не отрываясь от написания кода, и очистить ее позже.

Большинство разработчиков используют интерактивное перебазирование, чтобы придать функциональной ветке аккуратность перед слиянием с основной базой кода. Они могут склеить незначительные коммиты, удалить устаревшие элементы и в целом навести порядок в ветке, прежде чем выполнить перенос в «официальную» историю проекта. Со стороны будет казаться, что для разработки функции потребовалось лишь несколько коммитов и тщательное планирование.

Оценить эффективность интерактивного перебазирования можно, взглянув на получившуюся историю ветки main. В глазах окружающих вы будете блестящим разработчиком, который внедрил новую функцию с первого раза и без лишних коммитов. `Так интерактивное перебазирование помогает поддерживать порядок в истории проекта, а также сохраняет целесообразность каждого ее элемента.`

## 3. Что такое Git Cherry pick? (Git)

https://www.atlassian.com/ru/git/tutorials/cherry-pick#

`git cherry-pick` — это полезная команда, с помощью которой можно выборочно применить коммиты Git к текущей рабочей ветке HEAD. С ее помощью можно выбрать коммит из одной ветки и применить его к другой. Команда `git cherry-pick` — это удобный способ отменить изменения. Например, если коммит попал в ветку по ошибке, вы можете переключиться на нужную ветку и выполнить перенос.

Пользоваться командой `git cherry-pick` удобно, однако это не всегда оптимально. Она может привести к дублированию коммитов, поэтому нередко разработчики предпочитают обычное слияние. Таким образом, можно сказать, что команда `git cherry-pick` — средство эффективное, но узконаправленное.

Пример использования:
Если был обнаружен баг, важно как можно скорее предоставить исправление конечным пользователям. Рассмотрим пример, когда разработчик начинает создавать новую функцию. `В ходе работы обнаруживается существующий баг`, и разработчик создает специальный коммит для его исправления. Этот `коммит можно перенести прямо в основную ветку (main)`, чтобы исправить баг, прежде чем от него пострадают другие пользователи.

# CI/CD:

## 4. Что такое CI/CD?

Дополнить вопросы.


# Monitoring:

## 5. Мониторинг. Какой стек использовал? (Monitoring)(ОПЫТ)

Примеры использования мониторинга k8s и приложений на Linux:

### Использование стека grafana + prometheus + node exporter:
Для мониторинга кластера k8s и приложений на Linux. Этот стек позволяет собирать метрики с кластера k8s и отображать их в графическом виде с помощью Grafana. Node exporter собирает метрики с узлов кластера, а Prometheus хранит их и обеспечивает возможность запросов.

Файл конфигурации для настройки сбора метрик Prometheus:
```
prometheus.yml
```
Команда для запуска Grafana:
```
docker run -d --name=grafana -p 3000:3000 grafana/grafana
```

### Использование Instana + Instana agents:
Для мониторинга приложений на Linux. Instana предоставляет возможность мониторинга приложений в реальном времени с помощью агентов, установленных на хостах.

Команда для установки агента Instana на хосте Linux:
```
wget -O - https://setup.instana.io/agent | sh -s YOUR_AGENT_KEY
```
Файл конфигурации для настройки агента Instana:
```
instana-config.yaml
```
Команда для запуска мониторинга в реальном времени:
```
instana-agent start
```

# Logs:

## 6. Логирование. Какой стек использовал? (Monitoring)(ОПЫТ)

Примеры использования логирования k8s и приложений на Linux:

### Использование Loki + grafana:
Для сбора и отображения логов приложений на Linux. Loki - это система сбора и отображения логов, которая интегрируется с Grafana для отображения логов в удобном виде.

Команда для установки Loki в кластере k8s:
```
helm repo add grafana https://grafana.github.io/helm-charts
helm install loki grafana/loki-stack
```
Файл конфигурации для настройки сбора логов Loki:
```
loki-config.yaml
```

## 7. Хранение логов и метрик. (Monitoring)(ОПЫТ)

`При выборе места хранения логов и метрик учитывайте требования к безопасности, резервному копированию и доступности данных`. Также убедитесь, что выбранное решение соответствует требованиям по производительности и масштабируемости.

Для хранения больших объемов данных можно использовать специализированные хранилища, такие как `Amazon S3`, `Google Cloud Storage` или `MinIO`.

Использование базы данных для хранения логов и метрик:

В качестве базы данных можно использовать `InfluxDB`, которая специализируется на хранении временных рядов данных, что подходит для хранения метрик.
Для хранения логов можно использовать `Elasticsearch`, который также позволяет выполнять полнотекстовый поиск и анализ логов.



# Вопросы из записей из iCloud - Виртуальный ассистент:
(Тех собес Сбер devices 1/2 и Тех собес Сбер devices 2/2)

## 1. Расскажие о себе (2 года). Задачи, которыми занимался сам, но не команда. (ОПЫТ)
Смарт-трейд. Лид автоматизации и джун devops. 
Задачи: 
  1. подготовка CI/CD, 
  2. написание Dockerfile, docker-compose.yml.
  3. конфигурация раннеров
  4. развитие инфраструктуры для прогона тестов (физ сервера Linux Ubuntu 20.04, 22.04. Сборка билдов, запуск тестов в docker в VNC).
Инструменты: 
  1. Gitlab + gitlab runner + gitlab ci
  2. Docker
  3. Selenoid, selenoid-ui, ggr, ggr-ui
  4. Allure-server

МТС-Банк. middle-Devops.
Задачи:
  1. мониторинг бд, серверов, приложений, docker контейнеров и k8s кластера
  2. адмнистрирование linux серверов и ios 
  3. развитие инфраструктуры для прогона тестов, работы приложений и бд
  4. развитие аппиум фермы
  5. деплои в k8s кластер и конфигурация helm chart'ов (ingress, pods, services, rs, deployment)
  6. написание пайплайнов, баш скриптов, ansible-playbook

## 2. На чем был CI/CD в проектах? (CI/CD)
Jenkins, GitHub Actions, GitLab

## 3. Какие аналоги HELM ты знаешь? (Helm)
`/Users/andreyshabunov/PhpstormProjects/skillbox-k8s/helm/7.4/7.4.md` - путь до файла по Helm в k8s

1. ### Kustomize:
    1. Похож на Dockerfile - `kustomization.yaml`
        1. После создания service.yaml + deployment.yaml -> kustomization.yaml кастомизирует их с заданными значениями
    2. Аналог helm
    3. Встроен в kubectl (v1.14+):
        1. kubectl apply -k === применит kustomize-манифесты
        2. kubectl delete -k === удалит их
        3. kubectl kustomize соберёт манифесты и выведет на экран
    4. Не шаблонизирует как helm
2. ### Jsonnet:
    1. `Jsonnet` - это ЯП и инструмент для генерации JSON и других форматов данных. Он позволяет создавать и управлять структурированными данными с помощью более компактного и выразительного синтаксиса.
    2. Основан на JSON
    3. Можно конвертировать в YAML
    4. Используется с ЯП:
        1. C
        2. Python
        3. Go
        4. PHP
        5. Ruby
    5. Jsonnet может предоставить более гибкий и мощный подход к генерации конфигураций, чем Helm

## 4. Есть ли отличия в синтаксисе провайдеров для Terraform при написание файлов? (Terraform)
Есть различия в синтаксисе провайдеров для Terraform при написании файлов конфигурации. 
Каждый провайдер имеет свои уникальные параметры и настройки, которые могут отличаться от других провайдеров. 
Например, у провайдера `AWS` могут быть свои уникальные параметры, отличающиеся от параметров провайдера `Google Cloud Platform`.

Кроме того, различные провайдеры могут поддерживать разные версии API и иметь разные способы авторизации и настройки доступа. 
Все это может отразиться на синтаксисе и структуре файлов конфигурации Terraform для каждого провайдера.

Поэтому при написании файлов конфигурации Terraform для различных провайдеров важно обращать внимание на документацию каждого провайдера и учитывать их уникальные особенности.

Пример `простого ресурса` `AWS S3` и аналогичного ресурса `Digital Ocean Spaces` в файле конфигурации Terraform:
```
# AWS S3
resource "aws_s3_bucket" "example" {
  bucket = "my-unique-bucket"
  acl    = "private"
}

# Digital Ocean Spaces
resource "digitalocean_spaces_bucket" "example" {
  name   = "my-unique-bucket"
  region = "nyc3"
  acl    = "private"
}
```
В этом примере видно, что параметры для создания бакета в облаке AWS S3 и Digital Ocean Spaces имеют некоторые различия. 
Например, у Digital Ocean Spaces есть параметр `region`, который отсутствует у AWS S3, зато у AWS S3 есть параметр `bucket`, который является обязательным. Также, у обоих провайдеров есть параметр `acl`, который задает права доступа к бакету, но возможно у них различные допустимые значения.

`bucket` - это обозначение хранилища (или контейнера) файлов в облаке. В случае AWS S3 и Digital Ocean Spaces, "bucket" представляет собой хранилище для файлов, к которому можно обращаться через API или веб-интерфейс.

`Простой ресурс` в Terraform представляет собой объект, который хотите создать или управлять в облаке (например, виртуальная машина, база данных, хранилище файлов и т. д.). "aws_s3_bucket" и "digitalocean_spaces_bucket" - это ресурсы, представляющие собой хранилища файлов в облаке AWS и Digital Ocean.


## 5. Как избежать ситуации чтобы 1 ресурс не изменили одновременно 2 разных человека и не перетёрли изменения друг друга? (Terraform)
Для избежания ситуации, когда два разных человека изменяют один и тот же ресурс в Terraform одновременно и могут перетереть изменения друг друга, можно использовать следующие рекомендации:

1. Разделение областей ответственности: разделите ресурсы между членами команды таким образом, чтобы каждый член команды был ответственен за определенные ресурсы. Это позволит избежать конфликтов при одновременном изменении одних и тех же ресурсов.

2. Использование блокировок: Terraform Enterprise и Terraform Cloud предоставляют возможность использования блокировок, которые предотвращают одновременное изменение одного и того же ресурса несколькими пользователями. Если вы используете Terraform в облаке, вы можете воспользоваться этой функцией.

3. Использование системы контроля версий: Используйте систему контроля версий, такую как Git, для управления вашими конфигурационными файлами Terraform. При этом важно следить за обновлениями и конфликтами при слиянии изменений.
Ревью изменений: Перед применением изменений с помощью Terraform, можно устроить ревью изменений, чтобы убедиться, что они не конфликтуют друг с другом и не приведут к нежелательным последствиям.

4. Коммуникация и согласование: Убедитесь, что у вашей команды есть хорошая коммуникация и согласование при работе с Terraform. Это позволит избежать конфликтов и перетирания изменений.


## 6. Отличие Git merge от Git rebase? (Git)

`Git merge` и `Git rebase` - это два различных способа объединения изменений из одной ветки в другую. Пример визуализации обоих методов:

У нас есть две ветки: "master" и "feature-branch". Обе ветки содержат одинаковые изменения.
```
   A---B---C  master
        \
         D---E  feature-branch
```
Теперь рассмотрим, что происходит при использовании Git merge и Git rebase:

`Git merge`: При использовании Git merge, изменения из "feature-branch" объединяются с "master" с сохранением истории каждой ветки. Это создает новый коммит, который объединяет изменения обеих веток.
```
   A---B---C------F  master
        \        /
         D---E---  feature-branch
```
`Git rebase`: При использовании Git rebase, изменения из "feature-branch" переносятся поверх "master", создавая новую историю коммитов без дополнительных коммитов слияния.
```
   A---B---C  master
            \
             D'---E'  feature-branch
```
### В каких случаях нужно использовать Git merge и Git rebase:

Используйте Git merge, если вы хотите сохранить оригинальную историю коммитов каждой ветки и хотите, чтобы объединенная ветка содержала дополнительный коммит слияния.

Используйте Git rebase, если вы хотите, чтобы история коммитов была линейной и чистой, без дополнительных коммитов слияния. Это может быть полезно, когда вы работаете над функциональным изменением и хотите, чтобы история коммитов выглядела более логично.

Важно помнить, что при использовании Git rebase следует быть осторожным, особенно если ваш репозиторий используется другими разработчиками, так как это изменяет историю коммитов и может привести к конфликтам, если другие разработчики уже скачали изменения из вашей ветки.


## 7. Какие технологии контейнеризации знаешь? (Docker)

Существует несколько технологий контейнеризации, но самые популярные из них включают:

`Docker`: Это, безусловно, самая известная и широко используемая технология контейнеризации. Docker позволяет упаковывать приложения и их зависимости в контейнеры, которые могут быть запущены на любой платформе, поддерживающей Docker.

`Kubernetes`: Это оркестратор контейнеров, который обеспечивает автоматизацию развертывания, масштабирования и управления контейнеризированными приложениями. Kubernetes позволяет управлять кластерами контейнеров и обеспечивает высокую доступность и масштабируемость.

`Podman`: Это инструмент контейнеризации, который предоставляет альтернативу Docker, позволяя запускать контейнеры без необходимости использования демона. Podman также обеспечивает совместимость с Docker и позволяет управлять контейнерами и образами.
https://habr.com/ru/companies/otus/articles/704384/ - `автоматически запускаемые контейнеры без root`:
1. `podman generate systemd --name mynginx --files /home/ashabunov/.config/systemd/user/container_mynginx.service` - сгенерировать юнит-файл systemd для автозапуска контейнера

`rkt (rktlet)`: Это еще один инструмент контейнеризации, разработанный CoreOS. Он предлагает альтернативу Docker и был создан с упором на безопасность и изоляцию контейнеров.

`LXC (Linux Containers)`: Это технология контейнеризации на уровне операционной системы, которая предоставляет возможность запускать несколько изолированных Linux-систем на одном хосте.

Каждая из этих технологий имеет свои особенности и преимущества, и выбор конкретной зависит от конкретных потребностей и задач проекта.


## 8. Зачем нужны контейнеры? (Docker)

Контейнеры предоставляют ряд преимуществ и решают несколько проблем, связанных с развертыванием и управлением приложениями. Вот несколько основных причин, почему контейнеры полезны:

1. `Портативность`: Контейнеры позволяют упаковать приложение и все его зависимости в единый пакет, который можно легко перенести и запустить на любой платформе, поддерживающей контейнеризацию. Это упрощает развертывание приложений и устраняет проблемы совместимости.

2. `Изоляция`: Контейнеры обеспечивают изоляцию приложений и их зависимостей, что означает, что каждое приложение работает в своей собственной среде, не вмешиваясь в другие контейнеры на хостовой системе. Это способствует безопасности и предотвращает конфликты между зависимостями различных приложений.

3. `Масштабируемость`: Контейнеры позволяют легко масштабировать приложения, запуская несколько экземпляров контейнеров одного и того же приложения на разных узлах или виртуальных машинах. Это обеспечивает высокую доступность и отказоустойчивость приложений.
`/Users/andreyshabunov/PhpstormProjects/skillbox-k8s/requests-limits-load-balance/auto-scale.md` - путь до файла по мастабированию в k8s
  1. `Горизонтальная масштабируемость` - Horizontal Pod Autoscaler (HPA) - масштабирование засчет увеличения кол-ва подов
  2. `Вертикальная масштабируемость` - Vertical Pod Autoscaler (VPA) - масштабирование засчет увеличения ресурсов подов
  3. `Автоматическое масштабирование` - Cluster Autoscaler - добавление/удаление НОД в зависимости от нужды

4. `Управление ресурсами`: Контейнеры позволяют управлять ресурсами, выделяемыми для каждого приложения, что позволяет оптимизировать использование ресурсов и повысить производительность.

5. `DevOps и CI/CD`: Контейнеры упрощают процессы разработки, тестирования и развертывания приложений, что делает их идеальным инструментом для DevOps-подхода и непрерывной поставки.

В целом, контейнеры обеспечивают более эффективное и надежное развертывание и управление приложениями, что делает их важным инструментом в современной разработке программного обеспечения.


## 9. Встал вопрос о том как заводить софт. 1 сотрудник говорит что контейнеры - это хипстерская чушь и можно доставлять код в виде .rpm пакетов (проверенная технология) и никакие контейнеры нам не нужны. (Docker)

Вот несколько аргументов в пользу контейнеров и .rpm пакетов:

### Преимущества контейнеров:
`Портативность`: Контейнеры упаковывают приложение и все его зависимости, что делает их легкими для переноса между различными средами разработки, тестирования и производства.
`Изоляция`: Контейнеры обеспечивают изоляцию приложений и их зависимостей, что предотвращает конфликты между различными версиями библиотек и зависимостей.
`Масштабируемость`: Контейнеры облегчают горизонтальное масштабирование приложений, что позволяет легко управлять нагрузкой и обеспечивать высокую доступность.

### Преимущества .rpm пакетов:
`Проверенная технология:` .rpm пакеты имеют долгую историю использования в мире Linux и являются широко принятым форматом для установки приложений.
`Управление зависимостями:` .rpm пакеты предоставляют механизм управления зависимостями, что может быть полезно при развертывании на старых или устаревших системах.

В итоге, выбор между контейнерами и .rpm пакетами зависит от конкретных потребностей проекта, особенностей инфраструктуры и предпочтений команды разработки. Оба подхода имеют свои преимущества, и важно тщательно взвесить их, прежде чем принимать решение.


## 10. Какая технология лежит в основе всей контейнеризации в Linux? (Docker)

В основе контейнеризации в Linux лежит технология `Linux-контейнеров (LXC)`, которая представляет собой механизм изоляции процессов и ресурсов внутри операционной системы Linux. LXC позволяет создавать и управлять контейнерами, которые являются легковесными виртуальными средами, изолированными друг от друга и от хост-системы.

Однако, следует отметить, что LXC представляет более `низкоуровневый подход к контейнеризации`, и его использование напрямую может потребовать дополнительных инструментов и управления. В более современных подходах к контейнеризации, таких как Docker, используется более высокоуровневый интерфейс для управления контейнерами, который упрощает их создание, управление и развертывание.

Таким образом, хотя LXC является основой контейнеризации в Linux, для более удобного и гибкого использования контейнеров часто применяются более высокоуровневые инструменты, такие как Docker, Kubernetes и т.д.




## Продолжить "Тех собес Сбер devices 1/2" с 19:40 мин