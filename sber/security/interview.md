# Список вопросов:

1. Что делает команда Linux `chmod 640`? (Linux)
2. Что такое `SWAP` и для чего используется? (Linux)
3. Откуда берется `SWAP` память? (Linux)
4. Что такое `Inode`? (Linux)
5. На боевом разделе закончились `Inode`, там лежат важные данные, которые никак нельзя удалять. Что сделать чтобы спасти ситуацию? (Linux)
6. Какую лучше выбрать ФС для большого кол-ва INODE? (Linux)
7. Что такое Load Average? Интерпретировать когда он у нас большой и пора паниковать, а когда всё в норме? (Linux)
8. Есть сервер (4 ядра, 16 гб памяти), LA в моменте - 17. Это плохо или хорошо? (Linux)
9. Чем отличаются протоклы UDP от TCP? (протоколы)
10. UDP не имеет никаких механизмов управления потоками данных, верно? Объяснить. (протоколы)
11. Есть ли фрагментация в UDP и TCP? (протоколы)
12. Есть задача - организовать трансляцию видео в сеть с какого-либо источника (с камеры или спутника) (протоколы)
13. Какие есть более подходящие для видео-трансляции протоколы? Приведи пример (протоколы)
14. Задача - развернуть k8s кластер с помощью kubeadm, kubelet, kubectl при помощи ansible. На какие бы роли ты разделил развертывание кластера? (Ansible)
15. Есть сервис, инветори, переменные (которые рендерятся в конфиг этого сервиса). Нужно написать плейбук так чтобы сервис рестартился только в том случае если произошли изменения в переменных. Как это сделать? (Ansible)
16. Что такое идемпотентность в Ansible? Приведи пример относительно Ansible (Ansible)
17. Чем отличается контейнеризация от виртуализации? (Docker)
18. Какие области можно выделить для сравнения контейнеризации от виртуализации? (Docker)
19. Кто управляет docker контейнерами на ОС, например, на Ubuntu сервере? (Docker)
20. Приходилось ли использовать multi-stage Dockerfile и для чего это нужно? (Docker)
21. Что в Docker отвечает за работу сети? (Docker)
22. Есть сеть Docker-0 (локальная сеть - 192.168). Кто делает этот нат? (Docker)
23. Мы хотим из реальной сети открыть какое-то кол-во портов в эту сеть (например, через docker-compose). Кто этим занимается? (Docker)
24. В чем разница развертывания БД через Deployment и StatefulSet? (k8s)
25. Приходилось ли настраивать dashboard в Grafana из полученных метрик Prometheus? (Grafana)
26. Что такое Zookeeper и для чего он нужен? (Kafka)
27. Что такое читатель/писатель (Consumer и Producer)? (Kafka)
28. 

## Собеседование со Сбер Кибер Безопасность:

-----------------------

# Вопросы из записи в iCloud (Тех собес Кибер Сбер 1/1):

# Linux:

## 1. Что делает команда Linux `chmod 640`? (Linux)

Команда Linux `chmod 640` устанавливает права доступа к файлу или директории в следующем формате:

- Владелец файла имеет права на чтение и запись (6).
- Пользователи, принадлежащие к группе владельца файла, имеют право на чтение (4).
- Остальные пользователи не имеют никаких прав доступа (0).

## 2. Что такое `SWAP` и для чего используется? (Linux)

SWAP - это область на жестком диске, которая используется операционной системой для временного хранения данных, когда физическая память (RAM) исчерпана. Когда оперативная память заполнена, неиспользуемые данные перемещаются в область SWAP, что позволяет системе продолжать работу, избегая ошибок из-за нехватки памяти.

SWAP обычно используется в случаях, когда недостаточно оперативной памяти для запуска приложений или процессов, и помогает избежать ситуации, когда система начинает использовать файл подкачки (swap file) или swap partition.

Примеры команд в Linux для работы с SWAP:

1. Просмотр текущего использования SWAP:
```
sudo swapon --show
```

2. Создание SWAP файла:
```
sudo fallocate -l 1G /swapfile   # создание файла размером 1 ГБ
sudo chmod 600 /swapfile         # установка прав доступа
sudo mkswap /swapfile            # создание SWAP области
sudo swapon /swapfile            # включение SWAP файла
```

3. Настройка SWAP при загрузке системы:
Добавьте запись о SWAP файле в файл `/etc/fstab` для автоматического монтирования при загрузке:
```
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
```

4. Отключение SWAP файла:
```
sudo swapoff /swapfile   # отключение SWAP файла
```

5. Удаление SWAP файла:
```
sudo rm /swapfile   # удаление SWAP файла
```

SWAP является важным компонентом для оптимизации использования памяти в Linux системах и может быть настроен и использован в зависимости от потребностей и конфигурации системы.

## 3. Откуда берется `SWAP` память? (Linux)

SWAP память в Linux берется из области жесткого диска, которая выделена для временного хранения данных, когда физическая оперативная память (RAM) заполнена. SWAP память используется в качестве дополнения к оперативной памяти и помогает избежать ситуаций нехватки памяти.

Если у вас на сервере 10 ГБ оперативной памяти и 1 ГБ SWAP, то SWAP не отнимает 1 ГБ от оперативной памяти. SWAP действует как дополнительное хранилище для данных, которые не могут быть хранены в оперативной памяти. Когда оперативная память заполняется, неиспользуемые данные перемещаются в область SWAP, чтобы освободить место в оперативной памяти для более важных данных.

Таким образом, оперативная память и SWAP работают вместе для обеспечения эффективного использования ресурсов системы. SWAP не отнимает оперативную память, но предоставляет дополнительное пространство для хранения данных в случае нехватки оперативной памяти.

## 4. Что такое `Inode`? (Linux)

## 5. На боевом разделе закончились Inode, там лежат важные данные, которые никак нельзя удалять. Что сделать чтобы спасти ситуацию? (Linux)
Когда на боевом разделе заканчиваются Inode, это может привести к невозможности создания новых файлов или к изменению существующих файлов, что может серьезно повлиять на работу сервера, особенно если там хранятся важные данные, включая базы данных.

Для решения этой проблемы можно предпринять следующие шаги:

1. Освободить место на разделе: Попробуйте удалить ненужные или временные файлы с раздела, чтобы освободить место для создания новых Inode. Однако, учитывайте, что удаление файлов может быть нежелательным, если они содержат важные данные.

2. Перенести данные на другой раздел: Создайте новый раздел с достаточным количеством Inode и скопируйте туда важные данные, включая базы данных. После этого можно будет работать с данными на новом разделе без ограничений Inode.

3. Увеличить количество Inode на текущем разделе: Возможно, потребуется изменить размер раздела с увеличением количества Inode. Это может быть сложным и требует опыта в администрировании Linux.

4. Оптимизировать использование Inode: Проверьте, есть ли файлы или папки, которые занимают большое количество Inode, и оптимизируйте их использование.

5. Связаться с профессионалами: В случае серьезных проблем с Inode, особенно если на разделе хранятся важные данные, рекомендуется обратиться к специалистам или администраторам Linux для помощи и решения проблемы без ущерба для данных.

Важно провести тщательный анализ ситуации и выбрать наиболее подходящий способ решения проблемы, чтобы избежать потери важных данных и минимизировать возможные проблемы с работой сервера.

## 6. На сервере не так много дискового пространства и было принято решение мигрировать на другой тип файловой системы. Какой тип файловой системы лучше выбрать? Какую лучше выбрать ФС для большого кол-ва INODE? (Linux)

Выбор файловой системы зависит от конкретных требований, но если вам нужно увеличить количество Inode, то следует выбирать файловые системы, которые хорошо масштабируются и поддерживают большое количество Inode.

Несколько хороших вариантов для увеличения количества Inode:

1. **XFS (eXtensible File System)**: XFS обеспечивает высокую производительность при работе с большими файловыми системами и большим количеством Inode. Он хорошо масштабируется и подходит для хранения большого объема данных, включая базы данных.

2. **ext4 с опцией "dir_index"**: ext4 - одна из самых распространенных файловых систем в Linux. При создании файловой системы ext4 с опцией "dir_index" (по умолчанию), это позволяет увеличить количество элементов в каталоге, что поможет увеличить количество доступных Inode.

3. **Btrfs (B-Tree File System)**: Btrfs предоставляет высокую степень надежности, быстродействия и поддерживает большое количество Inode. Он также имеет встроенную поддержку снимков и проверку целостности данных.

Примеры команд для создания файловой системы:
- Создание XFS: `mkfs.xfs /dev/sdX`
- Создание ext4 с опцией "dir_index": `mkfs.ext4 -O dir_index /dev/sdX`
- Создание Btrfs: `mkfs.btrfs /dev/sdX`

Убедитесь, что перед выбором и применением новой файловой системы у вас есть резервное копирование всех важных данных, так как процесс перехода на новую файловую систему потенциально опасен и может привести к потере данных, если не выполнен корректно.

## 7. Что такое Load Average? Интерпретировать когда он у нас большой и пора паниковать, а когда всё в норме? (Linux)

Load Average - это показатель, который отображает среднюю загрузку процессора за определенный период времени. В Linux этот показатель представлен тремя значениями, обозначаемыми как 1 минута, 5 минут и 15 минут.

Обычно Load Average выражается в виде чисел, например, 0.50 означает, что в среднем за указанный период времени процессор используется наполовину.

Интерпретация Load Average:
- Load Average меньше количества ядер процессора (например, 1 на сервере с 4 ядрами) - все в порядке, система спокойно обрабатывает загрузку.
- Load Average примерно равно количеству ядер - нормальная загрузка, но необходимо внимательно следить за изменениями.
- Load Average в 2-3 раза больше количества ядер - высокая загрузка, система может начать тормозить, возможно, необходимо оптимизировать работу сервисов или добавить ресурсы.
- Load Average значительно больше количества ядер - критическая ситуация, процессы могут начать зависать, возможно, уже происходит значительное замедление системы.

Для диагностики Load Average можно использовать команду `uptime` или `top`. При использовании команды `uptime` вы увидите текущий Load Average в формате 1 минуты, 5 минут и 15 минут. Пример:

```
$ uptime
  12:34:56 up 1 day, 2:03,  3 users,  load average: 0.15, 0.20, 0.30
```

Если вам нужно более подробное представление текущей загрузки системы, используйте команду `top`, где в верхней части отображается Load Average, а также другая полезная информация о работе системы. Команда `top` запускается в терминале, выход из нее производится с помощью нажатия клавиши `q`.

Наблюдайте за Load Average на своем сервере, чтобы рано обнаруживать проблемы и моментально реагировать на них.

## 8. Есть сервер (4 ядра, 16 гб памяти), LA в моменте - 17. Это плохо или хорошо? (Linux)

Load Average (LA) величиной 17 для сервера с 4 ядрами может считаться очень высоким. Обычно, если LA превышает количество физических ядер процессора в разы (например, LA больше 4 для 4-ядерного процессора), это указывает на серьезное перегруженное состояние системы.

В вашем случае, если Load Average держится на уровне 17 в течение продолжительного времени, это может означать, что процессы на сервере испытывают задержки из-за высокой загрузки процессора. Это может привести к замедлению работы сервера и возможному зависанию приложений.

В таких случаях следует принимать меры для снижения Load Average, такие как оптимизация процессов, распределение нагрузки, увеличение ресурсов сервера или масштабирование приложений. Также может быть полезно проанализировать процессы и узнать, какие из них являются основной причиной высокой загрузки процессора.

Таким образом, при LA величиной 17 на сервере с 4 ядрами стоит обратить на это внимание и принять соответствующие меры для улучшения производительности и стабильности системы.

## 9. Чем отличаются протоклы UDP от TCP? (протоколы)

## 10. UDP не имеет никаких механизмов управления потоками данных, верно? Объяснить. (протоколы)

UDP (User Datagram Protocol) не имеет механизмов управления потоками данных, в отличие от TCP (Transmission Control Protocol). В UDP данные передаются без установления соединения, отслеживания доставки сообщений, контроля целостности или повторной отправки потерянных пакетов. UDP просто отправляет пакет данных и не требует подтверждения о его доставке или обеспечения того, что данные были успешно получены.

Пример:

Есть приложение для стриминга видео в реальном времени, которое использует протокол UDP для передачи данных. Если смотреть видео через это приложение, поток видео передается в виде серии пакетов данных от сервера к устройству.

Если в процессе передачи один из пакетов данных потеряется или придет в неправильной последовательности, UDP не предпримет никаких действий для повторной отправки потерянного пакета или упорядочивания пакетов. Просто произойдет потеря фрагмента видео, что может привести к пропускам кадров или артефактам на экране.

Это отличается от TCP, где есть механизмы для контроля целостности данных, подтверждения доставки, упорядочивания пакетов и повторной передачи потерянных данных. TCP гарантирует более надежную доставку данных за счет управления потоком.

Таким образом, UDP обычно используется там, где небольшие задержки важнее надежной доставки данных, а пропуск потерянных пакетов не критичен (например, в потоковом видео, онлайн-играх). Однако, в других случаях, где целостность данных и повторная передача важны, TCP является более подходящим протоколом.

## 11. В каких случаях будет происходить фрагментация пакетов? Есть ли фрагментация в UDP и TCP? Что такое MTU сетевого интерфейса? Приведи пример фрагментации пакетов исходя из MTU сетевого интерфейса. (протоколы)

1) Фрагментация пакетов происходит, когда размер передаваемого пакета превышает максимальный размер передачи (Maximum Transmission Unit, MTU) для конкретной сети или промежуточного устройства. То есть, когда данных в одном пакете слишком много для передачи в одном фрейме или пакете, он разбивается на более мелкие фрагменты для передачи.

2) Фрагментация пакетов встречается в протоколе IP (Internet Protocol), который является частью стека протоколов TCP/IP. Как UDP, так и TCP могут быть фрагментированы, поскольку оба протокола используют IP для передачи данных по сети. Однако, процесс фрагментации более прозрачен для пользователей при использовании TCP, так как он обеспечивает механизм управления потоком и контроля целостности данных.

3) MTU (Maximum Transmission Unit) представляет собой максимальный размер пакета данных, который может быть передан через сетевой интерфейс без фрагментации. MTU может варьироваться в зависимости от типа сети и устройства. Например, для Ethernet MTU обычно равно 1500 байт.

Пример фрагментации пакетов исходя из MTU сетевого интерфейса:

Предположим, мы имеем два сетевых устройства с разными MTU - одно с MTU 1500 байт (Ethernet), а другое с MTU 1400 байт. Если мы попытаемся отправить пакет данных размером 2000 байт с одного устройства на другое, то в процессе передачи пакет будет разбит на фрагменты в соответствии с MTU каждого устройства.

В нашем примере, пакет размером 2000 байт будет фрагментирован на два фрагмента: один размером 1400 байт и второй размером 600 байт. Первый фрагмент будет передан на устройство с MTU 1400 байт, а второй - на устройство с MTU 1500 байт. Второе устройство сможет полностью принять и восстановить оригинальный пакет, в то время как первое устройство должно будет собрать два фрагмента для восстановления исходного пакета.

## 12. Есть задача - организовать трансляцию видео в сеть с какого-либо источника (с камеры или спутника). Есть для этого более специализированные протоколы. Какой протокол выбрать TCP или UDP? Почему? (протоколы)

При организации трансляции видео в сеть с камеры или спутника, часто используют специализированные протоколы передачи данных, такие как RTP (Real-Time Transport Protocol) в сочетании с UDP (User Datagram Protocol). 

Выгоды использования UDP в данном случае:
1. Низкая задержка: UDP обеспечивает более низкую задержку передачи пакетов по сравнению с TCP, что особенно важно для реального времени в видеопотоке.
2. Потери пакетов: UDP не обеспечивает гарантированную доставку пакетов, однако для видеопотока потеря нескольких пакетов реже критична, чем повышенная задержка из-за переотправки в TCP.
3. Пропускная способность: UDP более эффективно использует пропускную способность сети, так как не требует установления соединения и управления потоком, как TCP.

Рекомендуется выбирать UDP для трансляции видео потоков с учетом вышеуказанных преимуществ. Однако, при использовании UDP следует учитывать, что необходимо предусмотреть механизмы управления качеством обслуживания (QoS) и восстановления потерянных пакетов, если это необходимо для конкретного приложения или использования.

# 13. Какие есть более подходящие для видео-трансляции протоколы? Приведи пример (протоколы)

Для видео-трансляции обычно используют специализированные протоколы, предназначенные для обеспечения качественной передачи видео данных в реальном времени. Некоторые из наиболее распространенных протоколов для видео-трансляции это:

1. **RTP (Real-Time Transport Protocol)**: RTP используется для передачи аудио и видео данных в реальном времени через IP-сети. Он предоставляет механизм для кодирования, управления временем и управления потоком данных в пределах сессии трансляции.

2. **RTSP (Real-Time Streaming Protocol)**: RTSP обеспечивает управление медиапотоком между сервером и клиентом, позволяя управлять воспроизведением и потоком видео данных. RTSP может использоваться в сочетании с RTP для передачи видео.

3. **HLS (HTTP Live Streaming)**: HLS использует HTTP-протокол для трансляции видео контента в видеофайлы разного разрешения, что позволяет клиентам выбирать оптимальное качество видео в зависимости от их интернет-соединения. HLS широко используется для стримингового видеоконтента через Интернет.

4. **MPEG-DASH (Dynamic Adaptive Streaming over HTTP)**: MPEG-DASH позволяет стриминг видео с использованием HTTP-протокола, а также поддерживает адаптивное стримингование для автоматического изменения качества видео в зависимости от скорости интернет-соединения.

Каждый из этих протоколов имеет свои особенности и преимущества, и выбор протокола для конкретного случая зависит от специфики трансляции видео и требований к качеству и надежности передачи.

# 14. Задача - развернуть k8s кластер с помощью kubeadm, kubelet, kubectl при помощи ansible. На какие бы роли ты разделил развертывание кластера? (Ansible)

Для развертывания Kubernetes кластера с использованием Ansible можно разделить задачу на следующие роли:

1. **Установка зависимостей и настройка хостов (preparation)**: В этой роли выполняется установка необходимых пакетов и настройка хостов, чтобы они были готовы к установке Kubernetes. К примеру, здесь можно установить Docker, настроить сеть, установить и настроить необходимые зависимости.

2. **Установка и настройка Kubernetes (kubernetes)**: Эта роль ответственна за установку и настройку компонентов Kubernetes, таких как kubeadm, kubelet и kubectl. В этой роли также выполняется инициализация кластера, добавление узлов в кластер и настройка конфигураций.

3. **Настройка мастер-узлов (master_nodes)**: Эта роль занимается конфигурированием мастер-узлов кластера Kubernetes. Сюда можно включить действия по инициализации мастер-узла с помощью kubeadm, настройке Service Discovery, включению мастер-сервисов и другие действия настройки.

4. **Настройка рабочих узлов (worker_nodes)**: Данная роль выполняет конфигурацию рабочих узлов кластера Kubernetes. Здесь можно добавить узлы в кластер, настроить сеть между узлами, настроить kubelet и другие необходимые действия.

Примеры ролей в Ansible для развертывания Kubernetes кластера можно найти на GitHub или других ресурсах. В этих ролях обычно содержатся задачи для установки зависимостей, инициализации кластера, добавления узлов, настройки ролей мастера и рабочих узлов. Каждая роль содержит соответствующие задачи, шаблоны и переменные для выполнения необходимых действий.

# 15. Есть сервис, инветори, переменные (которые рендерятся в конфиг этого сервиса). Нужно написать плейбук так чтобы сервис рестартился только в том случае если произошли изменения в переменных. Как это сделать? (Ansible)

Для реализации данной задачи в Ansible можно воспользоваться фильтрами Jinja2 и условным выполнением задачи `в зависимости от изменений переменных`. В частности, можно сравнивать хэш переменных до и после применения рендеринга, и выполнять рестарт сервиса только в случае обнаружения изменений. Ниже приведен пример такого плейбука:

```yaml
---
- name: Обновление конфигурации и рестарт сервиса при изменениях
  hosts: all
  tasks:
    - name: Загрузка переменных из вашего источника (например, файл group_vars)
      include_vars:
        file: group_vars/{{ inventory_hostname }}.yml

    - name: Генерация конфигурационного файла сервиса с помощью Jinja2
      template:
        src: template.j2
        dest: /etc/service/config.conf
      register: config_change

    - name: Проверка изменений в конфигурационном файле
      set_fact:
        needs_restart: "{{ config_change.changed }}"

    - name: Рестарт сервиса, если необходимо
      systemd:
        name: service_name
        state: restarted
      when: needs_restart
```

В данном примере:

1. Переменные serivce_name и другие переменные загружаются из вашего источника переменных.
2. Затем используется шаблон Jinja2 (template.j2), чтобы сгенерировать конфигурационный файл сервиса.
3. Проверяется, были ли внесены изменения в конфигурационный файл с помощью переменной `config_change.changed`.
4. Переменная `needs_restart` устанавливается в true, если были изменения.
5. Затем происходит рестарт сервиса только при условии, что переменная `needs_restart` равна true.

С помощью данного плейбука можно обеспечить автоматический рестарт сервиса только в случае, если обнаружены изменения в переменных, применяемых к конфигурации сервиса.

-----------------------

Можно выполнить данную задачу при помощи `хендлеров` в Ansible. Хендлеры позволяют объединить действия и запустить их только в конце выполнения плейбука, если были сделаны изменения, требующие перезапуска сервиса.

Вот пример плейбука с использованием хендлеров:

```yaml
---
- name: Обновление конфигурации и рестарт сервиса при изменениях
  hosts: all
  tasks:
    - name: Загрузка переменных из вашего источника (например, файл group_vars)
      include_vars:
        file: group_vars/{{ inventory_hostname }}.yml

    - name: Генерация конфигурационного файла сервиса с помощью Jinja2
      template:
        src: template.j2
        dest: /etc/service/config.conf

  handlers:
    - name: restart service
      systemd:
        name: service_name
        state: restarted

    - name: check diff
      command: diff /etc/service/config.conf.new /etc/service/config.conf
      register: config_diff
      changed_when: config_diff.rc == 1

  listen: check diff
```

В данном примере:

1. Переменные service_name и другие переменные загружаются из вашего источника переменных.
2. Затем используется шаблон Jinja2 (template.j2), чтобы сгенерировать конфигурационный файл сервиса.
3. Хендлер `restart service` запускается только при наличии события, вызванного изменением `config_diff` (сравнение старого и нового конфигурационного файла).
4. Хендлер `check diff` отслеживает изменение конфигурационного файла и устанавливает факт `changed_when`, который определяет, были ли фактические изменения.

Оба подхода (с условным выполнением задачи и с использованием хендлеров) могут быть эффективны в данной задаче. Выбор подхода будет зависеть от предпочтений и требований проекта. Хендлеры полезны, когда нужно выполнить действие только по завершении плейбука после всех манипуляций с переменными.

# 16. Что такое идемпотентность в Ansible? Приведи пример относительно Ansible (Ansible)

Идемпотентность в Ansible означает, что при многократном выполнении плейбука результат остается тем же, даже если задача уже была выполнена ранее. Система считается идемпотентной, если ее состояние не меняется при повторном применении того же действия или операции.

Пример идемпотентной задачи в Ansible:

```yaml
- name: Установка пакета nginx
  apt:
    name: nginx
    state: present
```

В этом примере Ansible будет устанавливать пакет `nginx` с помощью модуля `apt`, но если он уже установлен, модуль будет проверять его наличие и не выполнит установку заново. Это пример идемпотентной задачи, которая не будет менять результат при повторном выполнении плейбука.

Еще один пример:

```yaml
- name: Копирование конфигурационного файла
  copy:
    src: /path/to/source.conf
    dest: /path/to/destination.conf
```

В данном примере задача копирования файла не изменяет результат при повторном выполнении, если исходный файл не изменился. Это также является примером идемпотентной задачи.

Идемпотентность в Ansible важна, потому что позволяет гарантировать, что система остается в желаемом состоянии даже при многократном выполнении плейбуков. Благодаря этому, вы можете уверенно применять плейбуки к своей инфраструктуре, зная, что результаты будут предсказуемыми и стабильными.

# 17. Чем отличается контейнеризация от виртуализации? (Docker)

Контейнеризация и виртуализация являются двумя разными концепциями, хотя и обе позволяют упаковать и изолировать приложения и их зависимости для более эффективного управления и развертывания.

1. **Виртуализация:**
   - Виртуализация позволяет создавать виртуальные машины, которые эмулируют физические компьютеры с помощью гипервизора.
   - Каждая виртуальная машина имеет свою операционную систему, ядро и ресурсы, такие как процессор, память и диск, полностью изолированные от других виртуальных машин.
   - Использование виртуализации требует больших объемов ресурсов для запуска нескольких виртуальных машин.
   - Примеры виртуализационных платформ: VMware, VirtualBox, Hyper-V.

2. **Контейнеризация (Docker):**
   - Контейнеризация позволяет упаковывать приложения и их зависимости в контейнеры, которые могут быть запущены на одном хосте без необходимости эмуляции всей операционной системы.
   - Контейнеры используют общее ядро операционной системы и разделяют ресурсы хоста, что делает их более легкими и эффективными по сравнению с виртуальными машинами.
   - Docker является одной из самых популярных платформ для контейнеризации, обеспечивая простой способ создания, управления и развертывания контейнеров.
   - Каждый контейнер содержит приложение, его зависимости и файловую систему, изолированные от других контейнеров, но использующие общие ресурсы хоста.
   - Контейнеры быстрее запускаются и используют меньше ресурсов, что делает их идеальным решением для микросервисной архитектуры.

Таким образом, основное различие между виртуализацией и контейнеризацией заключается в уровне изоляции и использовании ресурсов, где виртуализация эмулирует полный физический компьютер, а контейнеризация обеспечивает изоляцию на уровне приложений с более эффективным использованием ресурсов.

# 18. Какие области можно выделить для сравнения контейнеризации от виртуализации? (Docker)

Одним из ключевых отличий между контейнеризацией и виртуализацией, особенно в контексте Docker, являются следующие:

1. **Философия и подход:**
   - Виртуализация: Виртуальные машины эмулируют всю физическую машину, включая ОС и ресурсы, за счет чего получается высокая изоляция, но большее потребление ресурсов.
   - Контейнеризация (Docker): Контейнеры делят ядро ОС и используют общие системные библиотеки, что делает их легче и более эффективные в использовании ресурсов.

2. **Портативность и независимость:**
   - Docker контейнеры могут быть собраны и запущены на любой платформе, поддерживающей Docker, независимо от окружения и физической инфраструктуры.
   - Виртуальные машины могут быть менее портативными из-за необходимости установки гипервизора и операционной системы на каждом оборудовании.

3. **Оркестрация и масштабирование:**
   - Docker обеспечивает инструменты для оркестрации контейнеров, такие как Docker Swarm и Kubernetes, что облегчает управление и автоматизацию деплоя масштабируемых приложений.
   - Управление виртуальными машинами может быть более сложным из-за необходимости управления гипервизором и сетевыми настройками.

4. **Размер контейнеров:**
   - Контейнеры Docker обычно имеют небольшой размер благодаря общему использованию ядра ОС и файловой системы, что ускоряет их создание и развертывание, особенно при использовании автоматизированных средств CI/CD.

5. **Использование ресурсов:**
   - Docker контейнеры потребляют меньше ресурсов, чем виртуальные машины, так как они используют общие ресурсы хоста и не нуждаются в эмуляции всей ОС.

В целом, контейнеризация, особенно с использованием Docker, предоставляет более легковесное и гибкое решение для развертывания и управления приложениями по сравнению с традиционной виртуализацией, а также обладает большей портативностью и эффективностью использования ресурсов.

# 19. Кто управляет docker контейнерами на ОС, например, на Ubuntu сервере? (Docker)

На ОС, например Ubuntu сервере, Docker контейнерами управляет Docker Engine. Docker Engine является программным продуктом, который обеспечивает возможность создания, запуска и управления контейнерами Docker на хост-системе. Docker Engine включает в себя серверный движок, API и инструменты командной строки, необходимые для работы с контейнерами.

LXC (Linux Containers) - это другая технология контейнеризации, которая обеспечивает средства для работы с виртуализацией на уровне операционной системы. LXC был одним из первых инструментов для создания и управления контейнерами в Linux. Он предоставляет средства для создания изолированных окружений с собственной файловой системой и процессами.

Docker не был написан на базе LXC. Docker в своем нынешнем виде изначально использовал LXC в качестве интерфейса ядра Linux для виртуализации на уровне операционной системы, но с течением времени он перешел на свой собственный подход, который включает использование собственного инструмента libcontainer для управления контейнерами.

В целом, Docker и LXC выполняют похожие функции по созданию и запуску контейнеров, но Docker обладает более широкими возможностями и инструментами управления, в то время как LXC сконцентрирован на базовых функциях виртуализации на уровне операционной системы.

# 20. Приходилось ли использовать multi-stage Dockerfile и для чего это нужно? (Docker)

Да, использование multi-stage Dockerfile в Docker практике довольно распространено и имеет свои преимущества. Multi-stage Dockerfile позволяет создавать более эффективные и компактные образы контейнеров, а также упрощает процесс сборки и развертывания приложений.

Основными целями использования multi-stage Dockerfile являются:

1. **Уменьшение размера образа:** С помощью multi-stage Dockerfile можно создать образ, который содержит только необходимые компоненты и библиотеки для работы приложения, исключив из него лишние зависимости. Это помогает уменьшить размер образа и ускорить его развертывание.

2. **Улучшение производительности:** Благодаря многоэтапной сборке можно эффективно управлять запуском различных этапов сборки образа. Это позволяет ускорить процесс пересборки образа при внесении изменений в приложение, так как Docker переиспользует результаты предыдущих этапов.

3. **Отделение среды разработки от производственной среды:** Multi-stage Dockerfile позволяет разделить этапы сборки и среды, используемые для разработки и для производства. Например, на этапе разработки может использоваться полный образ с инструментами отладки и зависимостями для удобства разработчиков, в то время как в конечном образе для производства могут быть только необходимые компоненты.

Использование multi-stage Dockerfile помогает сделать процесс сборки, развертывания и управления образами более эффективным и автоматизированным, что в итоге способствует улучшению работы с контейнеризированными приложениями.

# 21. Что в Docker отвечает за работу сети? (Docker)

В Docker за работу сети отвечает подсистема Docker Networking. Docker Networking обеспечивает средства для управления сетевыми аспектами контейнеров, включая создание, настройку и управление сетевыми интерфейсами, маршрутизацией трафика между контейнерами и доступом к внешним сетевым ресурсам.

Основные компоненты подсистемы Docker Networking включают:

1. **Network Drivers (Драйверы сети):** Docker поддерживает различные типы сетевых драйверов, которые обеспечивают разные модели сетевого взаимодействия между контейнерами. Некоторые из них включают bridge, overlay, macvlan, и другие.

2. **Network Models (Модели сети):** Docker позволяет создавать собственные сети для контейнеров, группируя их в специальные сети, такие как bridge, overlay и другие. Это позволяет контролировать трафик между контейнерами и предоставлять им изолированные сетевые пространства.

3. **Service Discovery and Load Balancing (Обнаружение служб и балансировка нагрузки):** Docker Networking может предоставлять механизмы для автоматического обнаружения служб и балансировки нагрузки между контейнерами, помогая обеспечить надежную и масштабируемую работу приложений.

4. **Networking APIs (Сетевые API):** Docker предоставляет API для управления сетевыми аспектами контейнеров, позволяя программным образом настраивать сетевые параметры и взаимодействовать с сетевыми драйверами.

В целом, Docker Networking обеспечивает разнообразные возможности для создания и управления сетевыми средами контейнеризированных приложений, что делает его мощным инструментом для разработчиков и администраторов систем.

# 22. Есть сеть Docker-0 (локальная сеть - 192.168). Кто делает этот нат? (Docker)

Обычно сеть Docker-0 (docker0) и NAT (сетевой адресный перевод) в Docker настраиваются и управляются самим Docker Engine. Когда Docker создает сети для контейнеров, он также настраивает соответствующие NAT правила на хостовой машине с помощью iptables, чтобы обеспечить связь контейнеров с внешним миром.

Иными словами, Docker Engine автоматически создает NAT-правила на хостовой машине для контейнеров, позволяя им общаться с внешней сетью через IP-адреса хостовой машины. Docker выполняет роль NAT-шлюза, обеспечивая связь и маршрутизацию сетевого трафика между контейнерами и внешними сетями.

Это позволяет контейнерам работать в изолированных сетевых средах, но при этом иметь доступ к ресурсам и сервисам вне контейнера. Docker управляет созданием, настройкой и удалением этих правил NAT, облегчая для разработчиков и администраторов работу с контейнеризированными приложениями и сетевыми настройками.

# 23. Мы хотим из реальной сети открыть какое-то кол-во портов в эту сеть (например, через docker-compose). Кто этим занимается? (Docker)

Для открытия портов из реальной сети в сеть Docker (например, сеть Docker-0), вам необходимо настроить проброс портов (port forwarding) на хостовой машине, где работает Docker Engine. Это позволит перенаправить трафик с определенных портов хоста на порты внутри сети Docker, где работают ваши контейнеры.

Для этого можно использовать инструменты Docker, такие как Docker Compose, для описания структуры сети и проброса портов. В файле `docker-compose.yml` можно настроить mapping портов контейнера на хостовую машину, чтобы пробросить трафик с внешней сети в контейнер.

Например, в файле `docker-compose.yml` можно указать порт на хостовой машине, который будет проброшен на порт внутри контейнера:

```yaml
version: '3.7'
services:
  web:
    image: nginx:latest
    ports:
      - "8080:80"
```

В данном примере порт 8080 хостовой машины будет проброшен на порт 80 контейнера с сервисом Nginx.

Dалее, Docker Engine обеспечивает маршрутизацию трафика, поступающего на открытые порты хостовой машины, на соответствующие порты контейнеров в сети Docker, где они запущены. Таким образом, Docker выполняет роль по передаче трафика между внешней сетью и сетью Docker, обеспечивая доступ к контейнеризированным приложениям извне.

# 24. В чем разница развертывания БД через Deployment и StatefulSet? (k8s)

Deployment и StatefulSet являются двумя различными контроллерами Kubernetes, предназначенными для управления развертыванием приложений, и не только в различных случаях, но и с разными потребностями.

1. **Deployment**:
   - Deployment используется для развертывания приложений, работающих в режиме репликации (желательно, чтобы все реплики были идентичны).
   - Deployment обеспечивает механизм быстрого развертывания, масштабирования и обновления приложений, где состояние реплик не имеет значения.
   - Когда один контейнер с приложением умирает, Deployment автоматически запустит новый контейнер для замены.
   - Важно отметить, что Deployment не обеспечивает гарантию уникальности и жизненного цикла имени хоста (hostname), сохранение данных между перезапусками и так далее.

2. **StatefulSet**:
   - StatefulSet используется для развертывания приложений, у которых важно сохранить уникальность и устойчивость имени хоста, например, баз данных или служб с состоянием.
   - StatefulSet обеспечивает стабильные названия хостов, управление жизненным циклом подов и гарантирует уникальность и устойчивость идентификаторов.
   - StatefulSet обеспечивает учет порядка идентификации подов и создание стабильных сетевых и хранилищ данных.

Что касается сохранения данных при сбое пода с базой данных в обоих случаях (через Deployment и StatefulSet), то да, данные могут быть потеряны, поскольку контейнеры по умолчанию хранят данные во временной файловой системе, которая теряется при перезапуске. Однако, для поддержания сохранности данных в обоих случаях можно использовать внешние хранилища (например, PersistentVolume и PersistentVolumeClaim), что позволит сохранить данные в персистентном хранилище и предотвратить их потерю при сбое.

# 25. Приходилось ли настраивать dashboard в Grafana из полученных метрик Prometheus? (Grafana)

Да, создание и настройка дашборда в Grafana на основе метрик, собранных Prometheus, довольно распространенная практика. Для этого вам потребуется выполнить следующие шаги:

1. **Установить и настроить Prometheus**:
   Убедитесь, что у вас установлен Prometheus и настроены правила сбора метрик с помощью `node_exporter` на ваших Ubuntu серверах.

2. **Установить и настроить Grafana**:
   Установите Grafana, подключите к нему Prometheus в качестве источника данных, используя URL, где прослушивается Prometheus сервер.

3. **Создание дашборда**:
   - В Grafana создайте новый дашборд и добавьте панели с нужными метриками. Вы можете выбрать тип графика, настройки временного диапазона, агрегирование и другие параметры.
   - Для выбора источника данных и построения запросов используйте язык PromQL (Prometheus Query Language). Этот язык позволяет выбирать и фильтровать метрики, вычислять агрегированные значения и применять различные операции.

4. **Добавление фильтров и параметров в запросы**:
   - PromQL позволяет использовать различные функции и операторы для фильтрации данных, вычисления статистик и преобразования метрик.
   - Вы можете также использовать метки метрик для группировки, фильтрации и отображения данных на дашборде.

Хотя знание PromQL может быть полезным для более сложных запросов и фильтрации метрик, не обязательно иметь специальный язык программирования для простого составления базовых запросов. Grafana предоставляет удобный интерфейс для визуального создания запросов и фильтров, который упрощает процесс создания дашбордов.

Если у вас возникнут конкретные вопросы или проблемы при настройке дашбордов в Grafana с использованием метрик Prometheus, не стесняйтесь обращаться за дополнительной помощью.

# 26. Что такое Zookeeper и для чего он нужен? (Kafka)

Apache Zookeeper - это высокодоступный сервис для обеспечения координации, управления конфигурацией, обеспечения безопасности и обновлений в распределенных приложениях. Он широко используется в таких распределенных системах, как Apache Kafka, Hadoop и другие.

Для чего используется Zookeeper в контексте Apache Kafka?

1. **Координация брокеров**: Zookeeper отслеживает структуру брокеров в кластере Kafka, обновляет информацию о брокерах и обеспечивает их надежную работу. Это важно для обнаружения и обработки отказов в кластере.

2. **Управление конфигурацией**: Zookeeper хранит метаданные о темах, партициях, конфигурации и доступных брокерах Kafka. Это позволяет брокерам и клиентам получать информацию о состоянии кластера и выполнять соответствующие действия.

3. **Обеспечение согласованности**: Zookeeper обеспечивает сервис блокировки, который позволяет клиентам координировать доступ к общим ресурсам в распределенной среде, что важно для обеспечения целостности и согласованности данных.

Таким образом, Zookeeper играет решающую роль в обеспечении надежной и согласованной работы Apache Kafka в распределенной среде.

# 27. Что такое читатель/писатель (Consumer и Producer)? (Kafka)

В контексте Apache Kafka, термины "читатель/писатель" и "консумер/продюсер" относятся к ролям, которые могут выполнять приложения или компоненты, работающие с Kafka. Давайте разберем каждую роль:

1. **Продюсер (Producer)**:
   - Продюсеры отвечают за публикацию (написание) сообщений в темы Kafka.
   - Продюсер отправляет сообщения в брокеры Kafka без необходимости знать, каким образом они будут обработаны или потреблены.
   - Продюсеры могут публиковать сообщения в одну или несколько тем Kafka.

2. **Консумер (Consumer)**:
   - Консумеры играют роль получателей (читателей) сообщений из тем Kafka.
   - Консумеры подписываются на тему и получают сообщения, которые были опубликованы в эту тему.
   - Консумеры могут читать сообщения сразу после их публикации или начинать чтение с последнего смещения (offset), хранящегося в Kafka.

Таким образом, **продюсер** и **консумер** представляют собой модели асинхронного обмена сообщениями в Kafka. Продюсеры пишут данные в темы Kafka, а консумеры читают эти данные для их обработки.

Надеюсь, эта информация поможет вам лучше понять, как работают роли "читатель/писатель" и "консумер/продюсер" в контексте Kafka и как они взаимодействуют друг с другом для обмена данными. Если у вас есть дополнительные вопросы, не стесняйтесь спрашивать!

# 28.


# 29.
# 30.

## Продолжить собес с 54:05 мин